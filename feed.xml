<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://krishna-das-m.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://krishna-das-m.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-04-10T13:38:50+00:00</updated><id>https://krishna-das-m.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Hypothesis testing- Part II- t-test</title><link href="https://krishna-das-m.github.io/blog/2024/hypothesis-testing2/" rel="alternate" type="text/html" title="Hypothesis testing- Part II- t-test"/><published>2024-11-30T15:04:00+00:00</published><updated>2024-11-30T15:04:00+00:00</updated><id>https://krishna-das-m.github.io/blog/2024/hypothesis-testing2</id><content type="html" xml:base="https://krishna-das-m.github.io/blog/2024/hypothesis-testing2/"><![CDATA[<p>Here I would like to discuss the two-sample or independent t-test where we test two independent samples. To make it more clear we, will use the <code class="language-plaintext highlighter-rouge">scipy</code> library to conduct the t-test</p> <p>As an example discussed in the previous section, we’ll test whether the average height of males in the US is different from those in the EU using Python. So the null hypothesis is that the population mean for the people in two regions are the same, and the alternative hypothesis is that the population mean for people in US are larger than those from EU. Assume we have two datasets: one for the US and one for the EU. \(H_0:\mu_{US}=\mu_{EU}\) \(H_A:\mu_{US}&gt;\mu_{EU}\) An alternate way of writing the above equation is to compare the differences in population means to zero. Zero here corresponds to our hypothesized value for the differences in means. \(H_0:\mu_{US}-\mu_{EU}=0\) \(H_A:\mu_{US}-\mu_{EU}&gt;0\)</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="n">scipy.stats</span> <span class="kn">import</span> <span class="n">ttest_ind</span>

<span class="c1"># Simulated heights (in cm) for males in the US and EU
</span><span class="n">us_heights</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">175</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>  <span class="c1"># Mean=175, SD=10
</span><span class="n">eu_heights</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mi">174</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>  <span class="c1"># Mean=170, SD=10
</span></code></pre></div></div> <p>The distribution of these two height more or less looks the same, with almost the same mean. Now let’s perform the t-test. For two-sample t-test we have consider the half of the p-value.</p> <h4 id="standardizing-test-statistic">Standardizing test-statistic</h4> <p>The z-scores are calculated as follows, \begin{equation} z= \frac{Sample~stat-population~parameter}{SE} \end{equation} In the two sample case, the test statistic denoted as $t$, uses a similar equation \begin{equation} t= \frac{difference~in~sample~stat- difference~in~population~parameter}{SE} \end{equation} \begin{equation} t= \frac{(\bar{x}<em>{US}-\bar{x}</em>{EU})- (\mu_{US}-\mu_{EU})}{SE(\bar{x}<em>{US}-\bar{x}</em>{EU})} \end{equation} The standard error is calculated as follows, \begin{equation} SE(\bar{x}<em>{US}-\bar{x}</em>{EU})\approx \sqrt{\frac{s^2<em>{US}}{n</em>{US}}+\frac{s^2<em>{EU}}{n</em>{EU}}} \end{equation} where \(s\) is the standard deviation of the variable and \(n\) is the sample size. If we assume the null hypothesis is true: \(H_0:\mu_{US}-\mu_{EU}=0 \implies t=\frac{(\bar{x}_{US}-\bar{x}_{EU})}{SE(\bar{x}_{US}-\bar{x}_{EU})}\) \n \(t=\frac{(\bar{x}_{US}-\bar{x}_{EU})}{\sqrt{\frac{s^2_{US}}{n_{US}}+\frac{s^2_{EU}}{n_{EU}}}}\)</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">xbar_us</span> <span class="o">=</span> <span class="n">us_heights</span><span class="p">.</span><span class="nf">mean</span><span class="p">()</span>
<span class="n">xbar_eu</span> <span class="o">=</span> <span class="n">eu_heights</span><span class="p">.</span><span class="nf">mean</span><span class="p">()</span>

<span class="n">s_us</span> <span class="o">=</span> <span class="n">us_heights</span><span class="p">.</span><span class="nf">std</span><span class="p">()</span>
<span class="n">s_eu</span> <span class="o">=</span> <span class="n">eu_heights</span><span class="p">.</span><span class="nf">std</span><span class="p">()</span>

<span class="n">us_n</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">us_heights</span><span class="p">)</span>
<span class="n">eu_n</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">eu_heights</span><span class="p">)</span>

<span class="nf">print</span><span class="p">(</span><span class="n">xbar_us</span><span class="p">,</span> <span class="n">xbar_eu</span><span class="p">)</span>
<span class="mf">177.97970220151245</span> <span class="mf">170.06544972344068</span>
<span class="nf">print</span><span class="p">(</span><span class="n">s_us</span><span class="p">,</span> <span class="n">s_eu</span><span class="p">)</span>
<span class="mf">7.967555003758265</span> <span class="mf">7.834602080144636</span>
<span class="nf">print</span><span class="p">(</span><span class="n">us_n</span><span class="p">,</span> <span class="n">eu_n</span><span class="p">)</span>
<span class="mi">3000</span> <span class="mi">3000</span>
</code></pre></div></div> <p>Now let’s calculate the test-statistic,</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Calculate the numerator of the test statistic
</span><span class="n">numerator</span> <span class="o">=</span> <span class="n">xbar_us</span> <span class="o">-</span> <span class="n">xbar_eu</span>

<span class="c1"># Calculate the denominator of the test statistic
</span><span class="n">denominator</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">s_us</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">us_n</span> <span class="o">+</span> <span class="n">s_eu</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">eu_n</span><span class="p">)</span>

<span class="c1"># Calculate the test statistic
</span><span class="n">t_stat</span> <span class="o">=</span> <span class="n">numerator</span><span class="o">/</span><span class="n">denominator</span>

<span class="c1"># Print the test statistic
</span><span class="nf">print</span><span class="p">(</span><span class="n">t_stat</span><span class="p">)</span>
<span class="mf">38.793036979639794</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Calculate the degrees of freedom
</span><span class="n">degrees_of_freedom</span> <span class="o">=</span> <span class="n">us_n</span> <span class="o">+</span> <span class="n">eu_n</span> <span class="o">-</span><span class="mi">2</span>

<span class="c1"># Calculate the p-value from the test stat
</span><span class="n">p_value</span> <span class="o">=</span> <span class="n">t</span><span class="p">.</span><span class="nf">cdf</span><span class="p">(</span><span class="n">t_stat</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">degrees_of_freedom</span><span class="p">)</span>

<span class="c1"># Print the p_value
</span><span class="nf">print</span><span class="p">(</span><span class="n">p_value</span><span class="p">)</span>
</code></pre></div></div> <p>The same procedure can be done in a easier way using the <code class="language-plaintext highlighter-rouge">scipy</code> library</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Perform an independent t-test
</span><span class="n">t_stat</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="nf">ttest_ind</span><span class="p">(</span><span class="n">us_heights</span><span class="p">,</span> <span class="n">eu_heights</span><span class="p">)</span>

<span class="c1"># Set significance level
</span><span class="n">alpha</span> <span class="o">=</span> <span class="mf">0.05</span>

<span class="c1"># Output results
</span><span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">T-statistic: </span><span class="si">{</span><span class="n">t_stat</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">P-value: </span><span class="si">{</span><span class="n">p_value</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

<span class="k">if</span> <span class="n">p_value</span><span class="o">/</span><span class="mi">2</span> <span class="o">&lt;</span> <span class="n">alpha</span><span class="p">:</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">We reject the null hypothesis. There is a significant difference in average heights.</span><span class="sh">"</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">We fail to reject the null hypothesis. There is no significant difference in average heights.</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <p>output: <code class="language-plaintext highlighter-rouge">T-statistic: 40.020422168327485</code> <code class="language-plaintext highlighter-rouge">P-value: 0.0</code> <code class="language-plaintext highlighter-rouge">We reject the null hypothesis. There is a significant difference in average heights.</code> <code class="language-plaintext highlighter-rouge">t-critical:1.6451077126390887</code></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/height_distribution2-480.webp 480w,/assets/img/height_distribution2-800.webp 800w,/assets/img/height_distribution2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/height_distribution2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/t-distribution2-480.webp 480w,/assets/img/t-distribution2-800.webp 800w,/assets/img/t-distribution2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/t-distribution2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div>]]></content><author><name></name></author><category term="ML-concepts"/><category term="statistics"/><category term="code"/><summary type="html"><![CDATA[two-sample t-test for hypothesis testing]]></summary></entry><entry><title type="html">Hypothesis testing- Part I</title><link href="https://krishna-das-m.github.io/blog/2024/hypothesis-testing1/" rel="alternate" type="text/html" title="Hypothesis testing- Part I"/><published>2024-11-28T15:04:00+00:00</published><updated>2024-11-28T15:04:00+00:00</updated><id>https://krishna-das-m.github.io/blog/2024/hypothesis-testing1</id><content type="html" xml:base="https://krishna-das-m.github.io/blog/2024/hypothesis-testing1/"><![CDATA[<h4 id="what-is-it">What is it?</h4> <p>Hypothesis testing is a fundamental statistical method used to validate claims or hypotheses. At its core, hypothesis testing aims to provide a structured approach to deciding whether there is enough evidence in a sample of data to support or reject a certain belief or claim about a population parameter.</p> <h4 id="the-null-hypothesis-h_0">The Null Hypothesis (\(H_0\))</h4> <p>The <strong>null hypothesis</strong> represents the default or status quo assumption. It assumes no significant change between the variables you are testing. The form of null hypothesis varies from one scenario to test to another: if you are testing a new drug, then the null hypothesis would be that the new drug has no effect. For example, If you test the average height of male in US is greater than those in EU, the null hypothesis is that there is no difference.</p> <h4 id="the-alternative-hypothesis-h_1">The Alternative Hypothesis (\(H_1\))</h4> <p>The purpose of hypothesis testing is to determine whether to reject or fail to reject the null hypothesis based on the gathered evidence. If there is little evidence against the null hypothesis, then we fail to reject the null hypothesis. If the null hypothesis is highly unlikely given the evidence, then we reject the null in favor of an alternative hypothesis \(H_{1}\). The alternative hypothesis depends on the specific test. Considering the same example above, the alternative hypothesis would be that average height of male in US does in fact differ from those in EU.</p> <h4 id="how-do-we-make-a-decision-significance-level-and-p-value">How Do We Make a Decision? Significance level and p-value</h4> <p>Once we define the null and alternative hypotheses, the next step is to assess the evidence so as to reject or fail to reject the null hypothesis. But how do we quantify this evidence in a way that allows for a clear and objective decision? At the heart of this process is the concept of the <strong>p-value</strong> and the <strong>significance level (\(\alpha\))</strong>. To put in a mathematical perspective, we loot at the probability of obtaining the observed data under the assumption that the null hypothesis is true. This probability threshold commonly called as significance level \(\alpha\), determines whether to reject the null hypothesis when the null hypothesis is true (Type I error). A common value for \(\alpha\) is \(5\%\). This means that there a \(5\%\) risk of rejecting the null hypothesis. i.e. believing there is a difference in the observed evidence when there actually isn’t.</p> <blockquote> <p>The <strong>p-value</strong> is the probability of observing the data—or something more extreme—assuming that the null hypothesis is true.</p> </blockquote> <p><strong>p-value</strong>provides a measure of how compatible the data is with the null hypothesis. A smaller p-value indicates that the observed data is less likely under the null hypothesis, providing stronger evidence against it. Now what p-values rejects the null hypothesis. For this there’s a threshold that we set based on specific circumstances.</p> <blockquote> <p>The <strong>significance level (\(\alpha\))</strong> is a threshold we set in advance to determine whether the p-value is small enough to reject the null hypothesis. In essence, \(\alpha\) defines the maximum probability of making a <strong>Type I error</strong>—rejecting the null hypothesis when it is actually true.</p> </blockquote> <p>The significance level represents our tolerance for risk in making an incorrect conclusion. A common value for \(\alpha\) is <strong>0.05</strong> (or 5%), although it can vary depending on the context. For example:</p> <ul> <li>In medical research, where making a false claim about a treatment’s effectiveness can have serious consequences, \(\alpha\) might be set to a stricter level, such as 0.01.</li> <li>In exploratory research, where the goal is to identify potential leads rather than make definitive claims, \(\alpha\) might be set to 0.1.</li> </ul> <p>If we choose \(\alpha = 0.05\), this means there is a <strong>5% risk of rejecting the null hypothesis when it is actually true</strong>. In other words, we are allowing for a 5% chance of observing results as extreme as those in the data (or more extreme) due to random sampling variability, even though the null hypothesis is correct. Another way to make a decision is using the test statistic. If the test-statistic is greater than the critical value then we reject the null hypothesis and vice-versa.</p> <h5 id="the-role-of-the-p-value-in-decision-making">The Role of the p-Value in Decision-Making</h5> <p>To decide whether to reject the null hypothesis, we compare the p-value to the significance level \(\alpha\):</p> <ul> <li>If the <strong>p-value ≤ \(\alpha\)</strong>, we <strong>reject the null hypothesis</strong>. This indicates that the data provides sufficient evidence to conclude that the null hypothesis is unlikely to be true.</li> <li>If the <strong>p-value &gt; \(\alpha\)</strong>, we <strong>fail to reject the null hypothesis</strong>. This means the data does not provide strong enough evidence against the null hypothesis, so we retain it (but we do not prove it to be true). <h4 id="balancing-significance-level-and-risk">Balancing Significance Level and Risk</h4> </li> </ul> <p>Choosing the significance level is a trade-off between sensitivity and specificity. Lowering \(\alpha\) (e.g., from 0.05 to 0.01) reduces the risk of Type I errors but increases the risk of <strong>Type II errors</strong> (failing to reject the null hypothesis when it is false). The choice of \(\alpha\) depends on the context and the consequences of making incorrect decisions.</p> <p>By combining the p-value with a carefully chosen significance level, hypothesis testing provides a rigorous and systematic way to assess the evidence, helping researchers make data-driven conclusions with confidence. Now that’s about the basic understanding of hypothesis testing. There are several statistical test available based on the nature of the data and the objective of the test. Some common types include:</p> <ol> <li><strong>One-Sample T-Test</strong>: Tests whether the mean of a single sample differs from a known value.</li> <li><strong>Two-Sample T-Test</strong>: Compares the means of two independent samples.</li> <li><strong>Paired T-Test</strong>: Compares means from the same group at different times.</li> <li><strong>Chi-Square Test</strong>: Tests the association between categorical variables.</li> <li><strong>ANOVA (Analysis of Variance)</strong>: Compares means among three or more groups.</li> </ol> <p>In the next part we will look at some of the commonly used statistical test.</p>]]></content><author><name></name></author><category term="ML-concepts"/><category term="statistics"/><category term="code"/><summary type="html"><![CDATA[Introduction to hypothesis testing]]></summary></entry><entry><title type="html">Maximum Likelihood Estimation- part II</title><link href="https://krishna-das-m.github.io/blog/2024/mle2/" rel="alternate" type="text/html" title="Maximum Likelihood Estimation- part II"/><published>2024-10-28T15:04:00+00:00</published><updated>2024-10-28T15:04:00+00:00</updated><id>https://krishna-das-m.github.io/blog/2024/mle2</id><content type="html" xml:base="https://krishna-das-m.github.io/blog/2024/mle2/"><![CDATA[<p>This page will be updated soon. Thank you for your interest.</p>]]></content><author><name></name></author><category term="ML-concepts"/><category term="statistics"/><category term="code"/><summary type="html"><![CDATA[MLE for continuous features]]></summary></entry><entry><title type="html">Maximum Likelihood Estimation- part I</title><link href="https://krishna-das-m.github.io/blog/2024/mle/" rel="alternate" type="text/html" title="Maximum Likelihood Estimation- part I"/><published>2024-10-25T15:04:00+00:00</published><updated>2024-10-25T15:04:00+00:00</updated><id>https://krishna-das-m.github.io/blog/2024/mle</id><content type="html" xml:base="https://krishna-das-m.github.io/blog/2024/mle/"><![CDATA[<p>In this post, we’ll dive into the concept of <strong>Maximum Likelihood Estimation (MLE)</strong>, particularly focusing on features that are discrete in nature. To make the discussion practical and relatable, we’ll consider the example of disease testing, building on the ideas discussed in my previous post, <a href="https://krishna-das-m.github.io/blog/2024/bayes-theorem/">Exploring Prior, Likelihood, and Posterior Distributions</a>. First, let’s get familiar with the intuition behind MLE.</p> <h3 id="what-is-maximum-likelihood-estimation-mle">What is Maximum Likelihood Estimation (MLE)?</h3> <p>Maximum Likelihood Estimation (MLE) is a statistical method used to estimate the parameters of a probability distribution. It does so by maximizing the <strong>likelihood function</strong>, which represents the probability of the observed data given specific parameters. In simpler terms, MLE helps us find the “best fit” parameters of a model based on the data we have.</p> <ul> <li><strong>Likelihood</strong>: The likelihood refers to the probability of observing the data for a given set of parameters.</li> <li><strong>MLE</strong>: MLE finds the parameter values that make the observed data most probable by maximizing the likelihood function.</li> </ul> <h3 id="example-estimating-the-probability-that-a-person-tests-positive-for-a-disease">Example: Estimating the Probability that a Person Tests Positive for a Disease</h3> <p>In our example, let’s say we want to estimate the probability that a randomly selected person tests positive for a certain disease. Since the test result is binary (either positive or negative), this is a classic case of a <strong>Bernoulli</strong> (or binomial) distribution problem.</p> <p>Let’s set it up mathematically.</p> <p>Suppose we have a random sample \(X_1, X_2, \dots, X_n\), where:</p> <ul> <li>\(X_i = 0\) if a randomly selected person tests <strong>negative</strong> for the disease.</li> <li>\(X_i = 1\) if a randomly selected person tests <strong>positive</strong> for the disease.</li> </ul> <p>Assuming that each test result is independent of the others (i.e., the \(X_i\) ‘s are independent Bernoulli random variables), we aim to estimate the parameter \(p\) , the probability that a person tests positive for the disease.</p> <h4 id="the-likelihood-function">The Likelihood Function</h4> <p>For \(n\) independent observations, the <strong>likelihood function</strong> is the joint probability of observing the data given the parameter \(p\). This can be written as:</p> <p>\begin{equation} L(p) = \prod_{i=1}^n P(X_i | p) \end{equation}</p> <p>For a Bernoulli distribution, the probability density function for each \(X_i\) is:</p> <p>\begin{equation} P(X_i = 1 | p) = p \quad \text{and} \quad P(X_i = 0 | p) = (1 - p) \end{equation}</p> <p>Thus, the likelihood function for the entire dataset is:</p> <p>\begin{equation} L(p) = \prod_{i=1}^n p^{X_i} (1 - p)^{1 - X_i} \end{equation}</p> <p>This represents the probability of observing the given test results (both positive and negative) for a specific value of \(p\).</p> <p>Our goal here is to estimate \(p\), which is the probability that a random individual will test positive for the disease. Let’s create a random sample as described mathematically above. We’ll also look at how sample size effects the likelihood.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="n">scipy.special</span> <span class="kn">import</span> <span class="n">comb</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="k">def</span> <span class="nf">samples</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">percent</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">k</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">N</span><span class="o">*</span><span class="n">percent</span><span class="p">)</span> <span class="c1"># success
</span><span class="err"> </span> <span class="err"> </span> <span class="n">trials</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">k</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">N</span> <span class="o">-</span> <span class="n">k</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">return</span> <span class="n">trials</span><span class="p">,</span> <span class="n">k</span>

<span class="n">trials_1</span><span class="p">,</span> <span class="n">k_1</span> <span class="o">=</span> <span class="nf">samples</span><span class="p">(</span><span class="n">N</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span><span class="n">percent</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">trials_2</span><span class="p">,</span> <span class="n">k_2</span> <span class="o">=</span> <span class="nf">samples</span><span class="p">(</span><span class="n">N</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span><span class="n">percent</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">trials_3</span><span class="p">,</span> <span class="n">k_3</span> <span class="o">=</span> <span class="nf">samples</span><span class="p">(</span><span class="n">N</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span><span class="n">percent</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
</code></pre></div></div> <p>We have created three random samples with same percentage of people tested positive for the disease (for comparison). Let’s assume we don’t know the exact probability \(p\) (we know it 0.2) of having the disease. Instead, we’ll consider a range of possible values for \(p\) and calculate the likelihood for each value. Here’s how we generate a range of values for \(p\) and compute the likelihood:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># probability of sucess
</span><span class="k">def</span> <span class="nf">success_prob</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">start</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span><span class="mf">1.0</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">h</span> <span class="o">=</span> <span class="p">(</span><span class="n">stop</span><span class="o">-</span><span class="n">start</span><span class="p">)</span><span class="o">/</span><span class="n">N</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">return</span> <span class="n">p</span>

<span class="n">p_1</span> <span class="o">=</span> <span class="nf">success_prob</span><span class="p">(</span><span class="n">N</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">p_2</span> <span class="o">=</span> <span class="nf">success_prob</span><span class="p">(</span><span class="n">N</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="n">p_3</span> <span class="o">=</span> <span class="nf">success_prob</span><span class="p">(</span><span class="n">N</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="c1"># Calculate the likelihood function
</span><span class="k">def</span> <span class="nf">likelihood</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">return</span> <span class="nf">comb</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span><span class="o">*</span> <span class="n">p</span><span class="o">**</span><span class="n">k</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">p</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="n">N</span><span class="o">-</span><span class="n">k</span><span class="p">)</span>

<span class="n">likelihood_p_1</span> <span class="o">=</span> <span class="nf">likelihood</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">k_1</span><span class="p">,</span> <span class="n">p_1</span><span class="p">)</span> <span class="c1"># Likelihood
</span><span class="n">likelihood_p_2</span> <span class="o">=</span> <span class="nf">likelihood</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="n">k_2</span><span class="p">,</span> <span class="n">p_2</span><span class="p">)</span>
<span class="n">likelihood_p_3</span> <span class="o">=</span> <span class="nf">likelihood</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">k_3</span><span class="p">,</span> <span class="n">p_3</span><span class="p">)</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/LikelihoodFunction-480.webp 480w,/assets/img/LikelihoodFunction-800.webp 800w,/assets/img/LikelihoodFunction-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/LikelihoodFunction.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>For small sample sizes (\(N=20\)), the likelihood curve is broad. This means a wide range of \(p\) values seem plausible — the data doesn’t provide much information to narrow down the estimate of \(p\). As the sample size increases (moving to \(N=50\) and \(N=100\)), the curve becomes narrower. This reflects that larger datasets provide more information, allowing us to pinpoint the most likely value of \(p\) with greater precision. The peak of each curve represents the <strong>maximum likelihood estimate (MLE)</strong>, the value of \(p\) that maximizes the likelihood function.</p> <p>Maximizing the <strong>likelihood</strong> to find MLE, directly can be cumbersome due to the product of many terms. However, we can simplify the process by taking the <strong>logarithm</strong> of the likelihood function. Since the natural logarithm is a monotonic function, maximizing the log-likelihood is equivalent to maximizing the likelihood itself. The log-likelihood function is:</p> <p>\begin{equation} \ell(p) = \log L(p) = \log \left( \prod_{i=1}^n p^{X_i} (1 - p)^{1 - X_i} \right) \end{equation}</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># define log-likelihood
</span><span class="k">def</span> <span class="nf">log_likelihood</span><span class="p">(</span><span class="n">trials</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">sum_trials</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">trials</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">sum_one_minus_trials</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">([(</span><span class="mi">1</span><span class="o">-</span> <span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">trials</span> <span class="err"> </span><span class="p">])</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">log_lik</span> <span class="o">=</span> <span class="n">sum_trials</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="o">+</span> <span class="n">sum_one_minus_trials</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">p</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">mle</span> <span class="o">=</span> <span class="n">p</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">log_lik</span><span class="p">)]</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">return</span> <span class="n">log_lik</span><span class="p">,</span> <span class="n">mle</span>

<span class="n">log_lik_1</span><span class="p">,</span> <span class="n">mle_1</span> <span class="o">=</span> <span class="nf">log_likelihood</span><span class="p">(</span><span class="n">trials_1</span><span class="p">,</span><span class="n">p_1</span><span class="p">)</span>
<span class="n">log_lik_2</span><span class="p">,</span> <span class="n">mle_2</span> <span class="o">=</span> <span class="nf">log_likelihood</span><span class="p">(</span><span class="n">trials_2</span><span class="p">,</span><span class="n">p_2</span><span class="p">)</span>
<span class="n">log_lik_3</span><span class="p">,</span> <span class="n">mle_3</span> <span class="o">=</span> <span class="nf">log_likelihood</span><span class="p">(</span><span class="n">trials_3</span><span class="p">,</span><span class="n">p_3</span><span class="p">)</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/LogLikelihood-480.webp 480w,/assets/img/LogLikelihood-800.webp 800w,/assets/img/LogLikelihood-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/LogLikelihood.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Just like the likelihood, the log-likelihood curve peaks at the MLE, which is indicated by the dashed red line in the plot. Notice how, for larger sample sizes, the log-likelihood curve becomes steeper around the MLE. This means that the likelihood sharply penalizes values of \(p\) that deviate from the MLE as we gather more data. The shape of the curves is consistent across sample sizes, but the curves shift downwards as \(N\) increases. This is a natural consequence of the log-likelihood being the sum of the log probabilities across all data points — with more data, this sum grows larger (in negative magnitude).<br/> The MLE turns out to be 0.2 which is nothing but the proportion of people who tested positive in the given sample. This is can be written as</p> <p>\begin{equation} \hat{p} = \frac{\sum_{i=1}^n X_i}{n} \end{equation}</p> <p>This tells us that the maximum likelihood estimate \(\hat{p}\) is simply the <strong>sample mean</strong> of the observed data.</p>]]></content><author><name></name></author><category term="ML-concepts"/><category term="statistics"/><category term="code"/><summary type="html"><![CDATA[MLE for discrete features]]></summary></entry><entry><title type="html">Exploring Prior, Likelihood, and Posterior Distributions</title><link href="https://krishna-das-m.github.io/blog/2024/bayes-theorem/" rel="alternate" type="text/html" title="Exploring Prior, Likelihood, and Posterior Distributions"/><published>2024-09-30T15:09:00+00:00</published><updated>2024-09-30T15:09:00+00:00</updated><id>https://krishna-das-m.github.io/blog/2024/bayes-theorem</id><content type="html" xml:base="https://krishna-das-m.github.io/blog/2024/bayes-theorem/"><![CDATA[<p>In this post, we’ll explore the relationship between <strong>prior distribution</strong>, <strong>likelihood</strong>, and <strong>posterior distribution</strong> using a practical example.</p> <h4 id="bayes-theorem">Bayes’ Theorem</h4> <p>Bayes’ Theorem helps us update our beliefs based on new evidence. Here’s the formula: \begin{equation} \overbrace{P(hypothesis | evidence)}^{\text{posterior}} = \frac{\overbrace{P(evidence| hypothesis)}^{\text{likelihood}} \overbrace{P(hypothesis)}^{\text{prior}}}{\underbrace{P(evidence)}_{\text{marginal}}} \end{equation}</p> <p>Where:</p> <ul> <li><strong>Posterior</strong>: How probable is our hypothesis given the observed evidence.</li> <li><strong>Likelihood</strong>: How probable is the evidence given that our hypothesis is true.</li> <li><strong>Prior</strong>: How probable was our hypothesis before observing the data.</li> <li><strong>Marginal</strong>: How probable is the new evidence under all possible hypothesis.</li> </ul> <hr/> <h4 id="the-scenario">The Scenario</h4> <p>Let’s walk through an example.</p> <p>Suppose you visit your doctor and get tested for a rare disease. Unfortunately, the test result is positive. Naturally, you want to know: “Given the positive result, what is the probability that I actually have the disease?” Since no medical test is 100% accurate, Bayes’ Theorem helps us answer this question. In the context of our current scenario, when comparing it to the general form of Bayes’ Theorem, the hypothesis we are testing is that a person has the disease (i.e., they test positive for it). The evidence corresponds to the observed data, specifically the results from the tests that indicate a positive outcome.</p> <hr/> <h4 id="breaking-down-the-terms">Breaking Down the Terms:</h4> <ol> <li> <p><strong>Prior Probability, \(P(Disease)\)</strong>:<br/> This is the probability of having the disease before considering the test result. It represents the incidence of the disease in the general population.<br/> For example, if the disease affects 1 in 1000 people, then:<br/> \(P(Disease) = 0.001\)</p> </li> <li> <p><strong>Likelihood, \(P(+ | Disease)\)</strong>:<br/> This is the probability of testing positive, given that you already have the disease. In other words, it’s the accuracy of the test in detecting the disease when it is present.<br/> Let’s assume the test has an accuracy of 99%, so:<br/> \(P(+ | Disease) = 0.99\)</p> </li> <li> <p><strong>Marginal, \(P(+)\)</strong>:<br/> This is the overall probability of testing positive, regardless of whether the person has the disease. It includes both true positives and false positives.<br/> It is calculated as:<br/> \(P(+) = P(Disease) P(+ | Disease) + P(Healthy) P(+ | Healthy)\)<br/> Here, \(P(Healthy) = 1 - P(Disease) = 0.999\), and \(P(+ | Healthy)\) is the probability of NOT having the disease and falsely identified positive by the test (1% = 0.01). So:<br/> \(P(+ | Healthy) = 0.01\)</p> </li> <li> <p><strong>Posterior Probability, \(P(Disease | +)\)</strong>:<br/> This is the updated probability of having the disease, given that the test result is positive. Using Bayes’ Theorem, we can compute this as:<br/> \(P(Disease | +) = \frac{P(Disease) P(+ | Disease)}{P(+) }\) Plugging in the values:<br/> \(P(Disease | +) = \frac{0.001 \times 0.99}{(0.001 \times 0.99) + (0.999 \times 0.01)} = 0.09016\)<br/> So, the probability that you actually have the disease, even after testing positive, is about <strong>9%</strong>.</p> </li> </ol> <hr/> <p>Now where do the distribution plots of prior, likelihood and posterior come from? Before diving into how we obtain the distributions for the <strong>prior</strong>, <strong>likelihood</strong>, and <strong>posterior</strong>, let’s introduce a change of variable to make the equation more intuitive. We’ll substitute <strong>Disease</strong> with <strong>\(\theta\)</strong>, which represents the probability that a person from the population will test positive. This allows us to express <strong>Bayes’ Theorem</strong> as:<br/> \begin{equation} P(\theta|+)=\frac{P(+|\theta)P(\theta)}{P(+)} \end{equation} Our goal is to estimate the parameter <strong>\(\theta\)</strong>, which is the probability that a random individual will test positive for the disease. To make this concept more concrete, let’s simulate a scenario where we conduct a total of 10 tests, out of which 2 people are positive (we’ll call this a <strong>success</strong>).</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="c1"># Create bernoulli trials
</span> <span class="n">N</span> <span class="o">=</span> <span class="mi">10</span> <span class="c1">#total trials
</span> <span class="n">nDisease</span> <span class="o">=</span> <span class="mi">2</span> <span class="c1"># success
</span>
 <span class="c1"># Create a list with Disease (D) and Healthy (H) results
</span> <span class="n">trials</span> <span class="o">=</span> <span class="p">[</span><span class="sh">"</span><span class="s">D</span><span class="sh">"</span><span class="p">]</span> <span class="o">*</span> <span class="n">nDisease</span> <span class="o">+</span> <span class="p">[</span><span class="sh">"</span><span class="s">H</span><span class="sh">"</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">N</span> <span class="o">-</span> <span class="n">nDisease</span><span class="p">)</span>

 <span class="c1"># Shuffle the sequence to randomize the order of trials
</span> <span class="n">random</span><span class="p">.</span><span class="nf">shuffle</span><span class="p">(</span><span class="n">trials</span><span class="p">)</span>

 <span class="nf">print</span><span class="p">(</span><span class="n">trials</span><span class="p">)</span>
 <span class="p">[</span><span class="sh">'</span><span class="s">H</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">H</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">H</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">H</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">H</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">H</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">H</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">D</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">H</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">D</span><span class="sh">'</span><span class="p">]</span>
</code></pre></div></div> <hr/> <h4 id="the-prior-distribution"><strong>The Prior Distribution</strong></h4> <p>Let’s assume we don’t have any specific information about the proportion of people who have the disease, so we don’t know the exact value of \(P(\theta)\). Instead of assuming a single fixed value, we’ll consider a range of possible values for \(P(\theta)\).<br/> To account for this uncertainty, we’ll generate 10 random values between 0 and 1, which will represent potential probabilities for the prevalence of the disease in the population. This helps us explore various possible scenarios when estimating the likelihood of having the disease based on a positive test result.<br/> Here’s how we generate these random values:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="n">scipy.stats</span> <span class="kn">import</span> <span class="n">beta</span>

<span class="c1"># Disease = np.random.random(10)
</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">N</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mi">10</span>
<span class="n">h</span> <span class="o">=</span> <span class="p">(</span><span class="n">stop</span><span class="o">-</span><span class="n">start</span><span class="p">)</span><span class="o">/</span><span class="n">N</span>
<span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
</code></pre></div></div> <p>At this stage, <code class="language-plaintext highlighter-rouge">theta</code> contains a set of values representing possible probabilities of having the disease. However, these values don’t yet form a probability distribution because the sum of \(P(\theta)\) is not equal to 1. If desired, we could adjust the range of <code class="language-plaintext highlighter-rouge">theta</code> (for example, using values from 0 to 10), but in that case, we would need to normalize the values.</p> <p>Next, we need to choose a distribution for the <strong>prior</strong>. A suitable choice is the <strong>beta distribution</strong>, which is defined over the interval \([0, 1]\), making it perfect for modeling probabilities like \(\theta\).</p> <p>We can specify the prior distribution using the beta distribution:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Define prior distribution
</span><span class="n">a</span> <span class="p">,</span> <span class="n">b</span><span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span>
<span class="n">dist</span> <span class="o">=</span> <span class="nf">beta</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="n">Ptheta</span> <span class="o">=</span> <span class="n">dist</span><span class="p">.</span><span class="nf">pdf</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
<span class="c1"># Normalize so that values sum to 1
</span><span class="n">Ptheta</span> <span class="o">=</span> <span class="n">Ptheta</span> <span class="o">/</span> <span class="nf">sum</span><span class="p">(</span><span class="n">Ptheta</span><span class="p">)</span>
<span class="c1"># print(pTheta)
</span></code></pre></div></div> <p>The array <code class="language-plaintext highlighter-rouge">Ptheta</code> gives us the prior probability distribution. This represents our <strong>prior belief</strong> about the possible values of \(P(\theta)\) before observing any new data, such as the results of the test.</p> <h4 id="the-likelihood"><strong>The Likelihood</strong></h4> <p><strong>The likelihood function</strong> is simply the joint probability of observing the data we have. For a set of test results, the likelihood function is expressed as:<br/> \(P(+|\theta)=\prod_i^N P(+_i|\theta)\) This is the product of the probabilities of observing each positive test result for a given \(\theta\). Specifically, the likelihood function for this binary event (positive or negative test result) can be written using the <strong>binomial distribution</strong>:</p> <p>\(P(+|\theta)=\binom{N}{k}\theta^k(1-\theta)^{N-k}\)</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Likelihood
</span><span class="n">PPositiveGiventheta</span> <span class="o">=</span> <span class="nf">comb</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">nDisease</span><span class="p">)</span><span class="o">*</span><span class="n">theta</span><span class="o">**</span><span class="n">nDisease</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">theta</span><span class="p">)</span><span class="o">**</span><span class="n">nHealthy</span>
</code></pre></div></div> <h4 id="the-posterior-distribution"><strong>The Posterior Distribution</strong></h4> <p>With both the <strong>prior</strong> and <strong>likelihood</strong> in hand, we can now calculate the <strong>posterior distribution</strong> using Bayes’ Theorem. The only remaining part to compute is the denominator of Bayes’ Theorem, which acts as a normalization factor, ensuring that the posterior probabilities sum to 1.</p> <p>Using the following Python code, we can calculate the <strong>marginal probability</strong> (the denominator) and the posterior:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># marginal probability
</span><span class="n">PPositive</span> <span class="o">=</span> <span class="nf">sum</span><span class="p">(</span><span class="n">PPositiveGiventheta</span> <span class="o">*</span> <span class="n">Ptheta</span><span class="p">)</span>
<span class="c1"># posterior probability
</span><span class="n">PthetaGivenPositive</span> <span class="o">=</span> <span class="n">PPositiveGiventheta</span><span class="o">*</span><span class="n">Ptheta</span> <span class="o">/</span> <span class="n">PPositive</span>
</code></pre></div></div> <p>Now let’s take a look at what we’ve calculated for each value of \(\theta\):</p> <table> <thead> <tr> <th>theta</th> <th>prior</th> <th>likelihood</th> <th>posterior</th> </tr> </thead> <tbody> <tr> <td>0.0</td> <td>0.0000</td> <td>0.0000</td> <td>0.0000</td> </tr> <tr> <td>0.1</td> <td>0.0545</td> <td>0.1937</td> <td>0.1106</td> </tr> <tr> <td>0.2</td> <td>0.0970</td> <td>0.3020</td> <td>0.3065</td> </tr> <tr> <td>0.3</td> <td>0.1273</td> <td>0.2335</td> <td>0.3110</td> </tr> <tr> <td>0.4</td> <td>0.1455</td> <td>0.1209</td> <td>0.1841</td> </tr> <tr> <td>0.5</td> <td>0.1515</td> <td>0.0439</td> <td>0.0697</td> </tr> <tr> <td>0.6</td> <td>0.1455</td> <td>0.0106</td> <td>0.0162</td> </tr> <tr> <td>0.7</td> <td>0.1273</td> <td>0.0014</td> <td>0.0019</td> </tr> <tr> <td>0.8</td> <td>0.0970</td> <td>0.0001</td> <td>0.0001</td> </tr> <tr> <td>0.9</td> <td>0.0545</td> <td>0.0000</td> <td>0.0000</td> </tr> </tbody> </table> <p>Starting with the <strong>prior</strong> column, we can see that, based on the beta distribution \(\beta(2,2)\), most of the prior probability is centered around middle values of \(\theta\). This reflects an initial belief that the probability of having the disease is likely to be between 0.4 and 0.6, while assigning smaller probabilities to extreme values close to 0 or 1. The <strong>likelihood</strong>, derived from the observed data, suggests that the most likely values for \(\theta\) are between 0.2 and 0.3. Specifically, the maximum likelihood estimate for \(\theta\) is 0.2, which corresponds to the proportion of positive test results observed in the sample. As a result, the <strong>posterior distribution</strong> represents an update to our prior belief based on the likelihood of the data. The posterior shifts the bulk of the probability away from the prior’s most likely values (around 0.4–0.6) and moves it toward the data-driven estimate of \(\theta\) around 0.2. If we look at the mean of the posterior,</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">posteriorMean</span> <span class="o">=</span> <span class="nf">sum</span><span class="p">(</span><span class="n">PDiseaseGivenPositive</span> <span class="o">*</span> <span class="n">theta</span><span class="p">)</span>
<span class="n">posteriorMean</span><span class="p">.</span><span class="nf">round</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="mf">0.285</span>
</code></pre></div></div> <p>We can perhaps understand this further via the following visualizations. When using a <strong>beta prior</strong> of \(\beta(2,2)\), we start with a fairly weak belief about the probability \(\theta\) (testing positive for the disease). This prior distribution is fairly spread out, indicating that we don’t have a strong belief in any particular value of \(\theta\). There’s no sharp peak—suggesting we are open to a wide range of possibilities for the true value of \(\theta\). The <strong>likelihood function</strong>, based on the observed data, peaks around \(\theta = 0.1\), indicating that the data suggests this is the most likely value for the probability of a positive test. However, since our sample size is small, the likelihood still has some spread, reflecting uncertainty in our estimate. The <strong>posterior distribution</strong>—in green—represents the updated belief after combining the prior with the likelihood. It shows a peak around \(\theta = 0.2\), reflecting that the data is suggesting a slightly higher value for \(\theta\). However, since we’re combining a weak prior and a small sample, the posterior still has noticeable spread, indicating uncertainty remains.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/distributions_prior_beta_2_2-480.webp 480w,/assets/img/distributions_prior_beta_2_2-800.webp 800w,/assets/img/distributions_prior_beta_2_2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/distributions_prior_beta_2_2.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/distributions_prior_beta_10_10-480.webp 480w,/assets/img/distributions_prior_beta_10_10-800.webp 800w,/assets/img/distributions_prior_beta_10_10-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/distributions_prior_beta_10_10.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Now, consider a stronger prior, \(\beta(10,10)\), along with a larger dataset (100 samples). The prior distribution is more concentrated, reflecting a stronger initial belief about \(\theta\)—in this case, that it’s around 0.5. The <strong>likelihood function</strong> with the larger sample is also much sharper and concentrated around \(\theta = 0.2\). This sharpness reflects the informativeness of the data: with more samples, the data has reduced uncertainty, and the peak clearly suggests that \(\theta = 0.2\) is the most likely value. Finally, the <strong>posterior distribution</strong> in this case is sharper and more concentrated around \(\theta = 0.2\), indicating much higher certainty about the estimate of \(\theta\). With the larger dataset, the prior has much less influence compared to the likelihood, which dominates and drives the sharper posterior.</p> <p>Now, let’s look what happens when we use the posterior distribution from the previous step as the new prior. This updated prior now reflects a more informed belief about the unknown parameter \(\theta\). Since this new prior is derived from the posterior of the previous round, it’s much more concentrated compared to the original prior we started with. We now have a much stronger belief that \(\theta\) lies within a narrow range (around 0.15 in this case). The likelihood function looks almost the same as in the previous figure and still shows a peak around the same value of \(\theta\), indicating that the observed data strongly suggests that \(\theta\) falls within a same range. The updated posterior distribution is even sharper and more concentrated than before, reflecting a very strong belief about the value of \(\theta\). Compared to the earlier posterior (based on a broader prior), this one is peaked around 0.12, showing that we now have an even greater degree of certainty about \(\theta\).<br/> The key takeaway here is that as we gather more data and update our beliefs (using Bayes’ Theorem), our estimates become more precise. The prior becomes more informative, and the posterior narrows further, reflecting reduced uncertainty about the unknown parameter .</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/distributions_prior_posterior-480.webp 480w,/assets/img/distributions_prior_posterior-800.webp 800w,/assets/img/distributions_prior_posterior-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/distributions_prior_posterior.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Bayesian updating is a powerful method that allows us to continuously refine our estimates as new data becomes available. This process is iterative: we start with an initial belief (the <strong>prior</strong>), update it with evidence (the <strong>likelihood</strong>), and obtain a revised belief (the <strong>posterior</strong>). The posterior then serves as the new prior for the next round of updates. Let’s see how this works in practice by performing <strong>Bayesian updating</strong> in Python.</p> <p>Below is a Python implementation that demonstrates the sequential nature of this process over 10 updates:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Bayesian updating
</span><span class="k">def</span> <span class="nf">bayesian_update</span><span class="p">(</span><span class="n">bayes_df</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">bayes_df</span> <span class="o">=</span> <span class="n">bayes_df</span><span class="p">[[</span><span class="sh">'</span><span class="s">theta</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">posterior</span><span class="sh">'</span><span class="p">]].</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">posterior</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">prior</span><span class="sh">'</span><span class="p">})</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">bayes_df</span><span class="p">[</span><span class="sh">'</span><span class="s">likelihood</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="nf">comb</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">nDisease</span><span class="p">)</span><span class="o">*</span><span class="n">theta</span><span class="o">**</span><span class="n">nDisease</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">theta</span><span class="p">)</span><span class="o">**</span><span class="n">nHealthy</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">marginal</span> <span class="o">=</span> <span class="p">(</span><span class="n">bayes_df</span><span class="p">[</span><span class="sh">'</span><span class="s">likelihood</span><span class="sh">'</span><span class="p">]</span><span class="o">*</span><span class="n">bayes_df</span><span class="p">[</span><span class="sh">'</span><span class="s">prior</span><span class="sh">'</span><span class="p">]).</span><span class="nf">sum</span><span class="p">()</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">bayes_df</span><span class="p">[</span><span class="sh">'</span><span class="s">posterior</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">bayes_df</span><span class="p">[</span><span class="sh">'</span><span class="s">likelihood</span><span class="sh">'</span><span class="p">]</span><span class="o">*</span><span class="n">bayes_df</span><span class="p">[</span><span class="sh">'</span><span class="s">prior</span><span class="sh">'</span><span class="p">])</span><span class="o">/</span><span class="n">marginal</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">posteriorMean</span> <span class="o">=</span> <span class="nf">sum</span><span class="p">(</span><span class="n">bayes_df</span><span class="p">[</span><span class="sh">'</span><span class="s">posterior</span><span class="sh">'</span><span class="p">]</span> <span class="o">*</span> <span class="n">bayes_df</span><span class="p">[</span><span class="sh">'</span><span class="s">theta</span><span class="sh">'</span><span class="p">])</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Posterior mean after </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s"> update is: </span><span class="si">{</span><span class="nf">round</span><span class="p">(</span><span class="n">posteriorMean</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>

<span class="err"> </span> <span class="err"> </span> <span class="k">return</span> <span class="n">bayes_df</span>

<span class="n">bayes_update_df</span> <span class="o">=</span> <span class="nf">bayesian_update</span><span class="p">(</span><span class="n">bayes_df</span><span class="p">,</span><span class="n">n</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div> <p>Running the above code produces the following results, showing how the <strong>posterior mean</strong> changes after each update:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Posterior</span> <span class="n">mean</span> <span class="n">after</span> <span class="mi">1</span> <span class="n">update</span> <span class="ow">is</span><span class="p">:</span> <span class="mf">0.136</span>
<span class="n">Posterior</span> <span class="n">mean</span> <span class="n">after</span> <span class="mi">2</span> <span class="n">update</span> <span class="ow">is</span><span class="p">:</span> <span class="mf">0.125</span>
<span class="n">Posterior</span> <span class="n">mean</span> <span class="n">after</span> <span class="mi">3</span> <span class="n">update</span> <span class="ow">is</span><span class="p">:</span> <span class="mf">0.119</span>
<span class="n">Posterior</span> <span class="n">mean</span> <span class="n">after</span> <span class="mi">4</span> <span class="n">update</span> <span class="ow">is</span><span class="p">:</span> <span class="mf">0.115</span>
<span class="n">Posterior</span> <span class="n">mean</span> <span class="n">after</span> <span class="mi">5</span> <span class="n">update</span> <span class="ow">is</span><span class="p">:</span> <span class="mf">0.113</span>
<span class="n">Posterior</span> <span class="n">mean</span> <span class="n">after</span> <span class="mi">6</span> <span class="n">update</span> <span class="ow">is</span><span class="p">:</span> <span class="mf">0.111</span>
<span class="n">Posterior</span> <span class="n">mean</span> <span class="n">after</span> <span class="mi">7</span> <span class="n">update</span> <span class="ow">is</span><span class="p">:</span> <span class="mf">0.11</span>
<span class="n">Posterior</span> <span class="n">mean</span> <span class="n">after</span> <span class="mi">8</span> <span class="n">update</span> <span class="ow">is</span><span class="p">:</span> <span class="mf">0.109</span>
<span class="n">Posterior</span> <span class="n">mean</span> <span class="n">after</span> <span class="mi">9</span> <span class="n">update</span> <span class="ow">is</span><span class="p">:</span> <span class="mf">0.108</span>
<span class="n">Posterior</span> <span class="n">mean</span> <span class="n">after</span> <span class="mi">10</span> <span class="n">update</span> <span class="ow">is</span><span class="p">:</span> <span class="mf">0.107</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/distributions_prior_posterior_10-480.webp 480w,/assets/img/distributions_prior_posterior_10-800.webp 800w,/assets/img/distributions_prior_posterior_10-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/distributions_prior_posterior_10.jpg" class="img-fluid rounded z-depth-1 mx-auto d-block" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>This illustrates the <strong>sequential nature of Bayesian updating</strong>. This iterative process is fundamental to <strong>Bayesian inference</strong> and demonstrates how our understanding of a parameter improves with each new piece of evidence, making Bayesian methods highly suitable for dynamic, real-world problems where data comes in sequentially over time.</p>]]></content><author><name></name></author><category term="ML-concepts"/><category term="statistics"/><category term="code"/><category term="probability"/><summary type="html"><![CDATA[Understanding the basics of Bayes' theorem]]></summary></entry></feed>
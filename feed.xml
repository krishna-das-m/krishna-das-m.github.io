<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://krishna-das-m.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://krishna-das-m.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-05-19T20:31:58+00:00</updated><id>https://krishna-das-m.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Understanding neural networks- Part I</title><link href="https://krishna-das-m.github.io/blog/2025/neural_netowrks_1/" rel="alternate" type="text/html" title="Understanding neural networks- Part I"/><published>2025-05-18T15:04:00+00:00</published><updated>2025-05-18T15:04:00+00:00</updated><id>https://krishna-das-m.github.io/blog/2025/neural_netowrks_1</id><content type="html" xml:base="https://krishna-das-m.github.io/blog/2025/neural_netowrks_1/"><![CDATA[<h2 id="step-1-defining-the-neural-network-structure-understanding-layers">Step 1: Defining the Neural Network Structure: Understanding Layers</h2> <p>Before diving into code, it’s essential to understand how a neural network is structured. At its core, a neural network is a system inspired by the human brain, consisting of layers of interconnected “neurons” that process data.</p> <h3 id="1-input-layer">1. <strong>Input Layer</strong></h3> <p>The input layer is the first layer of the network and serves as the gateway through which raw data enters the model. Each neuron in this layer represents one feature or attribute of the input data.</p> <p>For example, if you’re working with a dataset of handwritten digits (like the popular MNIST dataset), each image is typically 28×28 pixels, resulting in 784 input features (since 28 × 28 = 784). So, your input layer will have 784 neurons, each one receiving the pixel value of the corresponding location in the image.</p> <h3 id="2-hidden-layers">2. <strong>Hidden Layers</strong></h3> <p>Hidden layers are the intermediate layers between the input and output layers. These layers are where most of the computation happens. Each neuron in a hidden layer takes inputs from all the neurons in the previous layer, applies a weighted sum, adds a bias, and then passes the result through an <strong>activation function</strong> (like ReLU or sigmoid) to introduce non-linearity.</p> <p>The number of hidden layers and the number of neurons in each is up to you. A single hidden layer can work for many simple tasks, but more complex problems often benefit from deeper networks with multiple hidden layers.</p> <h3 id="3-output-layer">3. <strong>Output Layer</strong></h3> <p>The output layer is the final layer of the network, and its structure depends on the task you’re solving:</p> <ul> <li>For <strong>classification</strong>, the number of neurons equals the number of classes. For example, classifying digits 0–9 means having 10 output neurons, each one representing the probability of a particular digit.</li> <li>For <strong>regression</strong>, typically there’s just one output neuron, giving a continuous numerical value. <h3 id="example-well-use-a-simple-binary-classifier">Example We’ll Use: A Simple Binary Classifier</h3> <p>Let’s say we want to build a neural network that predicts whether a customer will make a purchase based on four input features. Let’s define a few training examples to show what the network will learn from. Each training example consists of 4 input values and 1 target output. In practice, these inputs would be normalized to keep the values between 0 and 1 for better learning performance. A sample part of the data is shown below:</p> </li> </ul> <table> <thead> <tr> <th>Age</th> <th>Income</th> <th>Browsing Time</th> <th>Items Viewed</th> <th>Purchase?</th> </tr> </thead> <tbody> <tr> <td>0.2</td> <td>0.8</td> <td>0.5</td> <td>0.6</td> <td>1</td> </tr> <tr> <td>0.6</td> <td>0.3</td> <td>0.2</td> <td>0.4</td> <td>0</td> </tr> <tr> <td>0.3</td> <td>0.5</td> <td>0.7</td> <td>0.8</td> <td>1</td> </tr> <tr> <td>0.9</td> <td>0.2</td> <td>0.1</td> <td>0.2</td> <td>0</td> </tr> </tbody> </table> <ol> <li><strong>Age</strong> (normalized between 0 and 1)</li> <li><strong>Annual Income</strong> (normalized)</li> <li><strong>Browsing Time on Website</strong> (in minutes, normalized)</li> <li><strong>Number of Items Viewed</strong> (normalized)</li> </ol> <p>The output will be a binary value:</p> <ul> <li><code class="language-plaintext highlighter-rouge">1</code> if the customer is likely to make a purchase</li> <li><code class="language-plaintext highlighter-rouge">0</code> if not <h3 id="network-architecture">Network Architecture</h3> <p>We’ll create a NN architecture as follows:</p> </li> <li><strong>Input Layer</strong>: 4 neurons (each corresponding to one input feature)</li> <li><strong>Hidden Layer</strong>: 3 neurons (fully connected to all input neurons)</li> <li><strong>Output Layer</strong>: 1 neuron (outputs a value between 0 and 1 — interpreted as purchase probability)</li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/neural_network-480.webp 480w,/assets/img/blog/neural_network-800.webp 800w,/assets/img/blog/neural_network-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/blog/neural_network.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Here the superscript $(m)$ represents the $m^{th}$ training example for the $i^{th}$ input feature. The neurons in the hidden layer $a_i^{[l]}$ represents the activation function of $i^{th}$ neuron in the layer $l$. In general we could represent a neuron in any layer as $a_i^{[l-1]}$ . Great! Now that we’ve defined the structure of the neural network, the next step is to <strong>initialize the parameters</strong> — specifically, the <strong>weights</strong> and <strong>biases</strong>. These parameters are what the network will learn during training.</p> <h2 id="step-2-initializing-parameters--weights-and-biases">Step 2: Initializing Parameters – Weights and Biases</h2> <p>Every connection between neurons in adjacent layers has a <strong>weight</strong>, and every neuron (except those in the input layer) has an associated <strong>bias</strong>. These are the values that the network updates during training to reduce the prediction error.</p> <h3 id="what-are-weights">What Are Weights?</h3> <p>Weights determine <strong>how strongly an input influences</strong> the output. Each weight connects a neuron in one layer to a neuron in the next layer.</p> <ul> <li>If a weight is large and positive, it strongly activates the next neuron in the next layer.</li> <li>If it’s negative, it inhibits the next neuron.</li> <li>If it’s close to zero, the input has little effect. <h3 id="what-are-biases">What Are Biases?</h3> <p>The <strong>bias</strong> is an extra parameter added to the weighted sum before applying the activation function. It allows the neuron to <strong>shift the activation function</strong>, enabling it to learn patterns that don’t pass through the origin. Without biases, the neural network’s flexibility would be significantly limited.</p> <h3 id="how-to-initialize-matrix-representation">How to Initialize: Matrix representation</h3> </li> </ul> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/activation_matrix_form-480.webp 480w,/assets/img/blog/activation_matrix_form-800.webp 800w,/assets/img/blog/activation_matrix_form-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/blog/activation_matrix_form.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>It is common to represent our neurons in the layers in matrix form. Let’s define the parameter shapes for our specific example:</p> <ul> <li><strong>Input Layer → Hidden Layer</strong> <ul> <li>Weights: <code class="language-plaintext highlighter-rouge">W1</code> will be a matrix of shape <strong>(3, 4)</strong><br/> (3 hidden neurons, each receiving 4 inputs)</li> <li>Biases: <code class="language-plaintext highlighter-rouge">b1</code> will be a vector of shape <strong>(3, 1)</strong><br/> (1 bias for each hidden neuron)</li> </ul> </li> <li><strong>Hidden Layer → Output Layer</strong> <ul> <li>Weights: <code class="language-plaintext highlighter-rouge">W2</code> will be a matrix of shape <strong>(1, 3)</strong><br/> (1 output neuron, connected to 3 hidden neurons)</li> <li>Bias: <code class="language-plaintext highlighter-rouge">b2</code> will be a scalar or a vector of shape <strong>(1, 1)</strong><br/> (bias for the output neuron) This setup assumes that we’re using <strong>column vectors</strong> for input examples (shape: 4 × 1). When initializing weights and biases, the goal is to start with small random values to break symmetry:</li> </ul> </li> <li><strong>Weights (<code class="language-plaintext highlighter-rouge">W1</code>, <code class="language-plaintext highlighter-rouge">W2</code>)</strong>: Initialized with small random numbers (e.g., drawn from a uniform or normal distribution). This randomness helps the neurons learn different features during training. Example: <div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  W1 = random values of shape (3, 4)
  W2 = random values of shape (1, 3)
</code></pre></div> </div> </li> <li><strong>Biases (<code class="language-plaintext highlighter-rouge">b1</code>, <code class="language-plaintext highlighter-rouge">b2</code>)</strong>: Usually initialized to <strong>zeros</strong>. Starting biases at zero is safe, and they’ll quickly move during training.</li> </ul>]]></content><author><name></name></author><category term="ML-concepts"/><category term="ML"/><summary type="html"><![CDATA[Defining the network architecture and intializing the NN parameters]]></summary></entry><entry><title type="html">Hypothesis testing- Part II- t-test</title><link href="https://krishna-das-m.github.io/blog/2024/hypothesis-testing2/" rel="alternate" type="text/html" title="Hypothesis testing- Part II- t-test"/><published>2024-11-30T15:04:00+00:00</published><updated>2024-11-30T15:04:00+00:00</updated><id>https://krishna-das-m.github.io/blog/2024/hypothesis-testing2</id><content type="html" xml:base="https://krishna-das-m.github.io/blog/2024/hypothesis-testing2/"><![CDATA[<p>Have you ever picked up a protein bar and wondered if it truly weighs what it says on the label? I mean, the packaging might claim it’s 20 grams, but how consistent is that across different countries? More specifically, are the 20g protein bars from the same brand identical in weight whether you buy them in India or Poland?</p> <p>This curiosity led me down a statistical rabbit hole—and that’s where the <strong>independent two-sample t-test</strong> comes in handy. In this post, I’ll walk you through the logic behind the test, how we can use Python’s <code class="language-plaintext highlighter-rouge">scipy</code> library to implement it, and whether my protein bars were indeed statistically similar across countries.</p> <h2 id="whats-an-independent-two-sample-t-test">What’s an Independent Two-Sample t-test?</h2> <p>The independent two-sample t-test (often just called a “t-test”) is used to determine whether the means of two independent groups are significantly different from each other. It assumes:</p> <ul> <li>The two groups are independent.</li> <li>The data in each group is normally distributed.</li> <li>The variances of the two groups are (roughly) equal.</li> </ul> <p>If you’re testing whether a new medication works better than a placebo, or in our case, if protein bars from India differ in weight from those in Poland, this test is your go-to.</p> <h2 id="the-protein-bar-dilemma">The Protein Bar Dilemma</h2> <p>Let’s set up the scenario. A company claims its protein bar weighs 20 grams. But when I randomly checked a few samples from stores in India and Poland, I noticed something odd. The bars didn’t weigh the same.</p> <p>So I decided to go all in: I collected (hypothetically) 100 protein bars from India and 100 from Poland. Here’s what I found:</p> <ul> <li><strong>India</strong>: Mean weight = 20.5g, Standard deviation = 1g</li> <li><strong>Poland</strong>: Mean weight = 19.5g, Standard deviation = 1g</li> </ul> <p>Now, the question is: <em>Are these differences just due to chance, or are they statistically significant?</em></p> <h2 id="running-the-t-test-in-python">Running the t-test in Python</h2> <p>We’ll use the <code class="language-plaintext highlighter-rouge">scipy.stats</code> module, which has a handy function <code class="language-plaintext highlighter-rouge">ttest_ind()</code> that performs the independent t-test.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">n_ind</span><span class="p">,</span> <span class="n">n_pln</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">100</span> <span class="c1"># sample size
</span><span class="n">xbar_ind</span><span class="p">,</span> <span class="n">xbar_pln</span> <span class="o">=</span> <span class="mf">20.5</span><span class="p">,</span> <span class="mf">19.5</span> <span class="err"> </span> <span class="err"> </span><span class="c1"># sample mean
</span><span class="n">s_ind</span><span class="p">,</span> <span class="n">s_pln</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span> <span class="err"> </span> <span class="err"> </span><span class="c1"># population std
</span>
<span class="n">protein_ind</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">20.5</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_ind</span><span class="p">)</span> <span class="c1"># sample distribution
</span><span class="n">protein_pln</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">normal</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="mf">19.5</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">n_pln</span><span class="p">)</span>
</code></pre></div></div> <p>Before diving into the test, it’s always good practice to look at the distribution of the sample data. So, I plotted histograms of the weights from both India and Poland. The distribution of these two masses more or less looks the same—both are roughly normal with a slight shift in their average values.</p> <p>This observation gives us a hint: although the shapes are similar, the means are slightly different, and that’s what we’ll test statistically.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/distribution_ind_pln-480.webp 480w,/assets/img/blog/distribution_ind_pln-800.webp 800w,/assets/img/blog/distribution_ind_pln-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/blog/distribution_ind_pln.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <h2 id="framing-the-hypothesis">Framing the Hypothesis</h2> <p>Now, in reality, we don’t know the <strong>true population mean</strong> (the actual average mass of <em>all</em> protein bars in each country). So, we use the <strong>sample means</strong> as our best estimates. Let \(\bar{x}_{ind}\) and \(\bar{x}_{pln}\) be the sample mean for the mass in India and Poland respectively. The difference between these two sample means is the test statistic for the hypothesis test.</p> <p>We’ll test whether the average weight of protein bar in the India is different from those in the Poland using Python. So the null hypothesis is that the population mean for the weight in two regions are the same, and the alternative hypothesis is that the population mean for mass of protein bar in India is larger than those from Poland.</p> <p>Assume we have two datasets: one for the India and one for the Poland.</p> <p>\(H_0:\mu_{ind}=\mu_{pln}\)   \(H_A:\mu_{ind}&gt;\mu_{pln}\)  </p> <p>An alternate way of writing the above equation is to compare the differences in population means to zero. Zero here corresponds to our hypothesized value for the differences in means.</p> <p>\(H_0:\mu_{ind}-\mu_{pln}=0\)   \(H_A:\mu_{ind}-\mu_{pln}&gt;0\)</p> <h4 id="standardizing-test-statistic">Standardizing test-statistic</h4> <p>The z-scores are calculated as follows,</p> \[z= \frac{Sample~stat-population~parameter}{SE}\] <p>In the two sample case, the test statistic denoted as \(t\), uses a similar equation</p> \[t= \frac{\Delta ~sample~stat- \Delta ~population~parameter}{SE}\] <p>If we use \(\bar{x}\) to denote the mean sample statistic,</p> \[t= \frac{(\bar{x}_{ind}-\bar{x}_{pln})- (\mu_{ind}-\mu_{pln})}{SE(\bar{x}_{ind}-\bar{x}_{pln})}\] <p>The standard error is calculated as follows,</p> \[SE(\bar{x}_{ind}-\bar{x}_{pln})\approx \sqrt{\frac{s^2_{ind}}{n_{ind}}+\frac{s^2_{pln}}{n_{pln}}}\] <p>where \(s\) is the standard deviation of the variable and \(n\) is the sample size. If we assume the null hypothesis is true:</p> \[H_0:\mu_{ind}-\mu_{pln}=0 \implies t=\frac{(\bar{x}_{ind}-\bar{x}_{pln})}{SE(\bar{x}_{ind}-\bar{x}_{pln})}\] \[t=\frac{(\bar{x}_{ind}-\bar{x}_{pln})}{\sqrt{\frac{s^2_{ind}}{n_{ind}}+\frac{s^2_{pln}}{n_{pln}}}}\] <p>First we’ll calculate the test-statistic manually.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># calculate test statistic manually
</span><span class="n">numerator</span> <span class="o">=</span> <span class="n">protein_ind</span><span class="p">.</span><span class="nf">mean</span><span class="p">()</span> <span class="o">-</span> <span class="n">protein_pln</span><span class="p">.</span><span class="nf">mean</span><span class="p">()</span> <span class="err"> </span> <span class="c1"># numerator of the test statistic
</span><span class="n">s_ind</span> <span class="o">=</span> <span class="n">protein_ind</span><span class="p">.</span><span class="nf">std</span><span class="p">(</span><span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span> <span class="err"> </span> <span class="c1"># std from sample
</span><span class="n">s_pln</span> <span class="o">=</span> <span class="n">protein_pln</span><span class="p">.</span><span class="nf">std</span><span class="p">(</span><span class="n">ddof</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">denominator</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">s_ind</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">n_ind</span> <span class="o">+</span> <span class="n">s_pln</span><span class="o">**</span><span class="mi">2</span><span class="o">/</span><span class="n">n_pln</span><span class="p">)</span> <span class="err"> </span><span class="c1"># denominator of the test statistic
</span><span class="n">t_stat</span> <span class="o">=</span> <span class="n">numerator</span><span class="o">/</span><span class="n">denominator</span> <span class="err"> </span><span class="c1"># Calculate the test statistic
</span><span class="nf">print</span><span class="p">(</span><span class="n">t_stat</span><span class="p">)</span>
</code></pre></div></div> <div class="language-md highlighter-rouge"><div class="highlight"><pre class="highlight"><code>output:
<span class="p">7.</span>280583232108425
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># calcualte p-value
</span><span class="n">dof</span> <span class="o">=</span> <span class="n">n_ind</span> <span class="o">+</span> <span class="n">n_pln</span> <span class="o">-</span><span class="mi">2</span> <span class="c1"># degrees of freedom
</span><span class="n">p_value</span> <span class="o">=</span> <span class="p">(</span><span class="n">t</span><span class="p">.</span><span class="nf">sf</span><span class="p">(</span><span class="nf">abs</span><span class="p">(</span><span class="n">t_stat</span><span class="p">),</span> <span class="n">df</span><span class="o">=</span><span class="n">dof</span><span class="p">))</span> <span class="c1"># p-value for right-tailed test
</span><span class="nf">print</span><span class="p">(</span><span class="n">p_value</span><span class="p">)</span>
</code></pre></div></div> <div class="language-md highlighter-rouge"><div class="highlight"><pre class="highlight"><code>output:
<span class="p">3.</span>827486051688527e-12
</code></pre></div></div> <h4 id="t-distribution">t-distribution</h4> <p>The test statistic follows a t-distribution and has a parameter “degrees of freedom”(dof). <em>t-distribution for small degrees of freedom has a fatter tails than normal distribution.</em> As we increase the degrees of freedom, the t-distribution gets closer to the normal distribution. So a normal distribution is a t-distribution with infinite degrees if freedom. Degrees of freedom is the maximum number of logically independent values in the data sample. In our two sample case, there are as many degrees of freedom as observations, minus two because we know two sample statistics, the mean of each group.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Perform an independent t-test using scipy
</span><span class="n">t_stat</span><span class="p">,</span> <span class="n">p_value</span> <span class="o">=</span> <span class="nf">ttest_ind</span><span class="p">(</span><span class="n">protein_ind</span><span class="p">,</span> <span class="n">protein_pln</span><span class="p">,</span> <span class="n">alternative</span> <span class="o">=</span> <span class="sh">'</span><span class="s">greater</span><span class="sh">'</span><span class="p">,</span> <span class="n">equal_var</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>

<span class="n">CL</span> <span class="o">=</span> <span class="mf">0.95</span> <span class="c1"># confidence level
</span><span class="n">alpha</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">CL</span> <span class="c1"># Set significance level
</span><span class="n">t_critical</span> <span class="o">=</span> <span class="n">scipy</span><span class="p">.</span><span class="n">stats</span><span class="p">.</span><span class="n">t</span><span class="p">.</span><span class="nf">ppf</span><span class="p">(</span><span class="n">q</span><span class="o">=</span><span class="n">CL</span><span class="p">,</span> <span class="n">df</span><span class="o">=</span><span class="n">dof</span><span class="p">)</span> <span class="c1"># critical t-value
</span>
<span class="c1"># Output results
</span><span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">t-statistic: </span><span class="si">{</span><span class="n">t_stat</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">p-value: </span><span class="si">{</span><span class="n">p_value</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
<span class="k">if</span> <span class="n">p_value</span> <span class="o">&lt;</span> <span class="n">alpha</span><span class="p">:</span>
<span class="err"> </span> <span class="err"> </span> <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">We reject the null hypothesis. There is a significant difference in average weight.</span><span class="sh">"</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
<span class="err"> </span> <span class="err"> </span> <span class="nf">print</span><span class="p">(</span><span class="sh">"</span><span class="s">We fail to reject the null hypothesis. There is no significant difference in average weight.</span><span class="sh">"</span><span class="p">)</span>
<span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">t-critical:</span><span class="si">{</span><span class="n">t_critical</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <div class="language-md highlighter-rouge"><div class="highlight"><pre class="highlight"><code>output:
t-statistic: 7.280583232108425
p-value: 3.827486051688527e-12
We reject the null hypothesis. There is a significant difference in average weight.
t-critical:1.6525857836172075
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">t_values</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">8</span><span class="p">,</span> <span class="mi">8</span><span class="p">,</span> <span class="mi">1000</span><span class="p">)</span>
<span class="n">t_dist</span> <span class="o">=</span> <span class="n">scipy</span><span class="p">.</span><span class="n">stats</span><span class="p">.</span><span class="n">t</span><span class="p">.</span><span class="nf">pdf</span><span class="p">(</span><span class="n">t_values</span><span class="p">,</span> <span class="n">dof</span><span class="p">)</span>

<span class="c1">## Plot the t-distribution
</span><span class="n">plt</span><span class="p">.</span><span class="nf">plot</span><span class="p">(</span><span class="n">t_values</span><span class="p">,</span> <span class="n">t_dist</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">t-distribution</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">axvline</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">t_stat</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="n">linestyle</span><span class="o">=</span><span class="sh">'</span><span class="s">--</span><span class="sh">'</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">r</span><span class="sh">'</span><span class="s">t-statistic $(t_0)$</span><span class="sh">'</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">fill_between</span><span class="p">(</span><span class="n">t_values</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">t_dist</span><span class="p">,</span> <span class="n">where</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">abs</span><span class="p">(</span><span class="n">t_values</span><span class="p">)</span> <span class="o">&gt;=</span> <span class="n">np</span><span class="p">.</span><span class="nf">abs</span><span class="p">(</span><span class="n">t_critical</span><span class="p">),</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">red</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">critical region</span><span class="sh">'</span><span class="p">)</span>

<span class="n">plt</span><span class="p">.</span><span class="nf">fill_between</span><span class="p">(</span><span class="n">t_values</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">t_dist</span><span class="p">,</span> <span class="n">where</span><span class="o">=</span><span class="n">np</span><span class="p">.</span><span class="nf">abs</span><span class="p">(</span><span class="n">t_values</span><span class="p">)</span> <span class="o">&lt;=</span> <span class="n">np</span><span class="p">.</span><span class="nf">abs</span><span class="p">(</span><span class="n">t_critical</span><span class="p">),</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">color</span><span class="o">=</span><span class="sh">'</span><span class="s">blue</span><span class="sh">'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sh">'</span><span class="s">Acceptance region</span><span class="sh">'</span><span class="p">)</span>
<span class="c1">## Plot annotations
</span><span class="n">plt</span><span class="p">.</span><span class="nf">xlabel</span><span class="p">(</span><span class="sh">'</span><span class="s">t-value</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">ylabel</span><span class="p">(</span><span class="sh">'</span><span class="s">Probability Density</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">title</span><span class="p">(</span><span class="sh">'</span><span class="s">t-distribution</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="sh">'</span><span class="s">best</span><span class="sh">'</span><span class="p">)</span>
<span class="n">plt</span><span class="p">.</span><span class="nf">text</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="mf">0.13</span><span class="p">,</span> <span class="sa">r</span><span class="sh">'</span><span class="s">p-value$=P(t&gt;|t_0|)$</span><span class="sh">'</span><span class="p">)</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/blog/t-distribution_ind_pln-480.webp 480w,/assets/img/blog/t-distribution_ind_pln-800.webp 800w,/assets/img/blog/t-distribution_ind_pln-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/blog/t-distribution_ind_pln.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>From the t-distribution we see that the t-statistic lies well outside the acceptance region, hence we must reject the null hypothesis. The t-test produces two key outputs:</p> <ul> <li>The <strong>t-statistic</strong> measures the size of the difference relative to the variation in the sample data.</li> <li>The <strong>p-value</strong> indicates the probability of observing the data (or something more extreme) assuming the null hypothesis is true. Since the p-value is less than the significance level ($\alpha = 0.05$), we reject the null hypothesis.</li> </ul>]]></content><author><name></name></author><category term="ML-concepts"/><category term="statistics"/><category term="code"/><summary type="html"><![CDATA[two-sample t-test for hypothesis testing]]></summary></entry><entry><title type="html">Hypothesis testing- Part I</title><link href="https://krishna-das-m.github.io/blog/2024/hypothesis-testing1/" rel="alternate" type="text/html" title="Hypothesis testing- Part I"/><published>2024-11-28T15:04:00+00:00</published><updated>2024-11-28T15:04:00+00:00</updated><id>https://krishna-das-m.github.io/blog/2024/hypothesis-testing1</id><content type="html" xml:base="https://krishna-das-m.github.io/blog/2024/hypothesis-testing1/"><![CDATA[<h4 id="what-is-it">What is it?</h4> <p>Hypothesis testing is a fundamental statistical method used to validate claims or hypotheses. At its core, hypothesis testing aims to provide a structured approach to deciding whether there is enough evidence in a sample of data to support or reject a certain belief or claim about a population parameter.</p> <h2 id="null-hypothesis-h_0">Null Hypothesis (\(H_0\))</h2> <p>The <strong>null hypothesis</strong> represents the default or status quo assumption. It assumes no significant change between the variables you are testing. The form of null hypothesis varies from one scenario to test to another: if you are testing a new drug, then the null hypothesis would be that the new drug has no effect. For example, If you test the average height of male in US is greater than those in EU, the null hypothesis is that there is no difference.</p> <h2 id="alternative-hypothesis-h_1">Alternative Hypothesis (\(H_1\))</h2> <p>The purpose of hypothesis testing is to determine whether to reject or fail to reject the null hypothesis based on the gathered evidence. If there is little evidence against the null hypothesis, then we fail to reject the null hypothesis. If the null hypothesis is highly unlikely given the evidence, then we reject the null in favor of an alternative hypothesis \(H_{1}\). The alternative hypothesis depends on the specific test. Considering the same example above, the alternative hypothesis would be that average height of male in US does in fact differ from those in EU.</p> <h2 id="how-do-we-make-a-decision-significance-level-and-p-value">How Do We Make a Decision? Significance level and p-value</h2> <p>Once we define the null and alternative hypotheses, the next step is to assess the evidence so as to reject or fail to reject the null hypothesis. But how do we quantify this evidence in a way that allows for a clear and objective decision? At the heart of this process is the concept of the <strong>p-value</strong> and the <strong>significance level (\(\alpha\))</strong>. To put in a mathematical perspective, we loot at the probability of obtaining the observed data under the assumption that the null hypothesis is true. This probability threshold commonly called as significance level \(\alpha\), determines whether to reject the null hypothesis when the null hypothesis is true (Type I error). A common value for \(\alpha\) is \(5\%\). This means that there a \(5\%\) risk of rejecting the null hypothesis. i.e. believing there is a difference in the observed evidence when there actually isn’t.</p> <blockquote> <p>The <strong>p-value</strong> is the probability of observing the data—or something more extreme—assuming that the null hypothesis is true.</p> </blockquote> <p><strong>p-value</strong>provides a measure of how compatible the data is with the null hypothesis. A smaller p-value indicates that the observed data is less likely under the null hypothesis, providing stronger evidence against it. Now what p-values rejects the null hypothesis. For this there’s a threshold that we set based on specific circumstances.</p> <blockquote> <p>The <strong>significance level (\(\alpha\))</strong> is a threshold we set in advance to determine whether the p-value is small enough to reject the null hypothesis. In essence, \(\alpha\) defines the maximum probability of making a <strong>Type I error</strong>—rejecting the null hypothesis when it is actually true.</p> </blockquote> <p>The significance level represents our tolerance for risk in making an incorrect conclusion. A common value for \(\alpha\) is <strong>0.05</strong> (or 5%), although it can vary depending on the context. For example:</p> <ul> <li>In medical research, where making a false claim about a treatment’s effectiveness can have serious consequences, \(\alpha\) might be set to a stricter level, such as 0.01.</li> <li>In exploratory research, where the goal is to identify potential leads rather than make definitive claims, \(\alpha\) might be set to 0.1.</li> </ul> <p>If we choose \(\alpha = 0.05\), this means there is a <strong>5% risk of rejecting the null hypothesis when it is actually true</strong>. In other words, we are allowing for a 5% chance of observing results as extreme as those in the data (or more extreme) due to random sampling variability, even though the null hypothesis is correct.</p> <p>Another way to make a decision is using the test statistic. A test statistic is defined as a quantity taken from a sample that is used for deciding whether to reject or accept the null hypothesis. The general formula for calculating a test statistic is:</p> \[test~statistic = \frac{Sample ~ statistic-Value ~ of ~ parameter~ according~to ~null}{Standard~error~(SE)~of~the~sample~statistic}\] <p>If the test-statistic is greater than the critical value then we reject the null hypothesis and vice-versa.</p> <h3 id="role-of-the-p-value-in-decision-making">Role of the p-Value in Decision-Making</h3> <p>To decide whether to reject the null hypothesis, we compare the p-value to the significance level \(\alpha\):</p> <ul> <li>If the <strong>p-value ≤ \(\alpha\)</strong>, we <strong>reject the null hypothesis</strong>. This indicates that the data provides sufficient evidence to conclude that the null hypothesis is unlikely to be true.</li> <li>If the <strong>p-value &gt; \(\alpha\)</strong>, we <strong>fail to reject the null hypothesis</strong>. This means the data does not provide strong enough evidence against the null hypothesis, so we retain it (but we do not prove it to be true).</li> </ul> <h2 id="balancing-significance-level-and-risk">Balancing Significance Level and Risk</h2> <p>Choosing the significance level is a trade-off between sensitivity and specificity. Lowering \(\alpha\) (e.g., from 0.05 to 0.01) reduces the risk of Type I errors but increases the risk of <strong>Type II errors</strong> (failing to reject the null hypothesis when it is false). The choice of \(\alpha\) depends on the context and the consequences of making incorrect decisions.</p> <p>By combining the p-value with a carefully chosen significance level, hypothesis testing provides a rigorous and systematic way to assess the evidence, helping researchers make data-driven conclusions with confidence. Now that’s about the basic understanding of hypothesis testing. There are several statistical test available based on the nature of the data and the objective of the test. Some common types include:</p> <ol> <li><strong>One-Sample T-Test</strong>: Tests whether the mean of a single sample differs from a known value.</li> <li><strong>Two-Sample T-Test</strong>: Compares the means of two independent samples.</li> <li><strong>Paired T-Test</strong>: Compares means from the same group at different times.</li> <li><strong>Chi-Square Test</strong>: Tests the association between categorical variables.</li> <li><strong>ANOVA (Analysis of Variance)</strong>: Compares means among three or more groups.</li> </ol> <p>In the next part we will look at some of the commonly used statistical test.</p>]]></content><author><name></name></author><category term="ML-concepts"/><category term="statistics"/><category term="code"/><summary type="html"><![CDATA[Introduction to hypothesis testing]]></summary></entry><entry><title type="html">Maximum Likelihood Estimation- part II</title><link href="https://krishna-das-m.github.io/blog/2024/mle2/" rel="alternate" type="text/html" title="Maximum Likelihood Estimation- part II"/><published>2024-10-28T15:04:00+00:00</published><updated>2024-10-28T15:04:00+00:00</updated><id>https://krishna-das-m.github.io/blog/2024/mle2</id><content type="html" xml:base="https://krishna-das-m.github.io/blog/2024/mle2/"><![CDATA[<p>This page will be updated soon. Thank you for your interest.</p>]]></content><author><name></name></author><category term="ML-concepts"/><category term="statistics"/><category term="code"/><summary type="html"><![CDATA[MLE for continuous features]]></summary></entry><entry><title type="html">Maximum Likelihood Estimation- part I</title><link href="https://krishna-das-m.github.io/blog/2024/mle/" rel="alternate" type="text/html" title="Maximum Likelihood Estimation- part I"/><published>2024-10-25T15:04:00+00:00</published><updated>2024-10-25T15:04:00+00:00</updated><id>https://krishna-das-m.github.io/blog/2024/mle</id><content type="html" xml:base="https://krishna-das-m.github.io/blog/2024/mle/"><![CDATA[<p>In this post, we’ll dive into the concept of <strong>Maximum Likelihood Estimation (MLE)</strong>, particularly focusing on features that are discrete in nature. To make the discussion practical and relatable, we’ll consider the example of disease testing, building on the ideas discussed in my previous post, <a href="https://krishna-das-m.github.io/blog/2024/bayes-theorem/">Exploring Prior, Likelihood, and Posterior Distributions</a>. First, let’s get familiar with the intuition behind MLE.</p> <h3 id="what-is-maximum-likelihood-estimation-mle">What is Maximum Likelihood Estimation (MLE)?</h3> <p>Maximum Likelihood Estimation (MLE) is a statistical method used to estimate the parameters of a probability distribution. It does so by maximizing the <strong>likelihood function</strong>, which represents the probability of the observed data given specific parameters. In simpler terms, MLE helps us find the “best fit” parameters of a model based on the data we have.</p> <ul> <li><strong>Likelihood</strong>: The likelihood refers to the probability of observing the data for a given set of parameters.</li> <li><strong>MLE</strong>: MLE finds the parameter values that make the observed data most probable by maximizing the likelihood function.</li> </ul> <h3 id="example-estimating-the-probability-that-a-person-tests-positive-for-a-disease">Example: Estimating the Probability that a Person Tests Positive for a Disease</h3> <p>In our example, let’s say we want to estimate the probability that a randomly selected person tests positive for a certain disease. Since the test result is binary (either positive or negative), this is a classic case of a <strong>Bernoulli</strong> (or binomial) distribution problem.</p> <p>Let’s set it up mathematically.</p> <p>Suppose we have a random sample \(X_1, X_2, \dots, X_n\), where:</p> <ul> <li>\(X_i = 0\) if a randomly selected person tests <strong>negative</strong> for the disease.</li> <li>\(X_i = 1\) if a randomly selected person tests <strong>positive</strong> for the disease.</li> </ul> <p>Assuming that each test result is independent of the others (i.e., the \(X_i\) ‘s are independent Bernoulli random variables), we aim to estimate the parameter \(p\) , the probability that a person tests positive for the disease.</p> <h4 id="the-likelihood-function">The Likelihood Function</h4> <p>For \(n\) independent observations, the <strong>likelihood function</strong> is the joint probability of observing the data given the parameter \(p\). This can be written as:</p> <p>\begin{equation} L(p) = \prod_{i=1}^n P(X_i | p) \end{equation}</p> <p>For a Bernoulli distribution, the probability density function for each \(X_i\) is:</p> <p>\begin{equation} P(X_i = 1 | p) = p \quad \text{and} \quad P(X_i = 0 | p) = (1 - p) \end{equation}</p> <p>Thus, the likelihood function for the entire dataset is:</p> <p>\begin{equation} L(p) = \prod_{i=1}^n p^{X_i} (1 - p)^{1 - X_i} \end{equation}</p> <p>This represents the probability of observing the given test results (both positive and negative) for a specific value of \(p\).</p> <p>Our goal here is to estimate \(p\), which is the probability that a random individual will test positive for the disease. Let’s create a random sample as described mathematically above. We’ll also look at how sample size effects the likelihood.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">from</span> <span class="n">scipy.special</span> <span class="kn">import</span> <span class="n">comb</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="k">def</span> <span class="nf">samples</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">percent</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">k</span> <span class="o">=</span> <span class="nf">int</span><span class="p">(</span><span class="n">N</span><span class="o">*</span><span class="n">percent</span><span class="p">)</span> <span class="c1"># success
</span><span class="err"> </span> <span class="err"> </span> <span class="n">trials</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">]</span> <span class="o">*</span> <span class="n">k</span> <span class="o">+</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">N</span> <span class="o">-</span> <span class="n">k</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">return</span> <span class="n">trials</span><span class="p">,</span> <span class="n">k</span>

<span class="n">trials_1</span><span class="p">,</span> <span class="n">k_1</span> <span class="o">=</span> <span class="nf">samples</span><span class="p">(</span><span class="n">N</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span><span class="n">percent</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">trials_2</span><span class="p">,</span> <span class="n">k_2</span> <span class="o">=</span> <span class="nf">samples</span><span class="p">(</span><span class="n">N</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span><span class="n">percent</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
<span class="n">trials_3</span><span class="p">,</span> <span class="n">k_3</span> <span class="o">=</span> <span class="nf">samples</span><span class="p">(</span><span class="n">N</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span><span class="n">percent</span><span class="o">=</span><span class="mf">0.2</span><span class="p">)</span>
</code></pre></div></div> <p>We have created three random samples with same percentage of people tested positive for the disease (for comparison). Let’s assume we don’t know the exact probability \(p\) (we know it 0.2) of having the disease. Instead, we’ll consider a range of possible values for \(p\) and calculate the likelihood for each value. Here’s how we generate a range of values for \(p\) and compute the likelihood:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># probability of sucess
</span><span class="k">def</span> <span class="nf">success_prob</span><span class="p">(</span><span class="n">N</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">start</span><span class="p">,</span> <span class="n">stop</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span><span class="mf">1.0</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">h</span> <span class="o">=</span> <span class="p">(</span><span class="n">stop</span><span class="o">-</span><span class="n">start</span><span class="p">)</span><span class="o">/</span><span class="n">N</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">p</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">return</span> <span class="n">p</span>

<span class="n">p_1</span> <span class="o">=</span> <span class="nf">success_prob</span><span class="p">(</span><span class="n">N</span><span class="o">=</span><span class="mi">20</span><span class="p">)</span>
<span class="n">p_2</span> <span class="o">=</span> <span class="nf">success_prob</span><span class="p">(</span><span class="n">N</span><span class="o">=</span><span class="mi">50</span><span class="p">)</span>
<span class="n">p_3</span> <span class="o">=</span> <span class="nf">success_prob</span><span class="p">(</span><span class="n">N</span><span class="o">=</span><span class="mi">100</span><span class="p">)</span>

<span class="c1"># Calculate the likelihood function
</span><span class="k">def</span> <span class="nf">likelihood</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">k</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">return</span> <span class="nf">comb</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">k</span><span class="p">)</span><span class="o">*</span> <span class="n">p</span><span class="o">**</span><span class="n">k</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">p</span><span class="p">)</span><span class="o">**</span><span class="p">(</span><span class="n">N</span><span class="o">-</span><span class="n">k</span><span class="p">)</span>

<span class="n">likelihood_p_1</span> <span class="o">=</span> <span class="nf">likelihood</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="n">k_1</span><span class="p">,</span> <span class="n">p_1</span><span class="p">)</span> <span class="c1"># Likelihood
</span><span class="n">likelihood_p_2</span> <span class="o">=</span> <span class="nf">likelihood</span><span class="p">(</span><span class="mi">50</span><span class="p">,</span> <span class="n">k_2</span><span class="p">,</span> <span class="n">p_2</span><span class="p">)</span>
<span class="n">likelihood_p_3</span> <span class="o">=</span> <span class="nf">likelihood</span><span class="p">(</span><span class="mi">100</span><span class="p">,</span> <span class="n">k_3</span><span class="p">,</span> <span class="n">p_3</span><span class="p">)</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/LikelihoodFunction-480.webp 480w,/assets/img/LikelihoodFunction-800.webp 800w,/assets/img/LikelihoodFunction-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/LikelihoodFunction.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>For small sample sizes (\(N=20\)), the likelihood curve is broad. This means a wide range of \(p\) values seem plausible — the data doesn’t provide much information to narrow down the estimate of \(p\). As the sample size increases (moving to \(N=50\) and \(N=100\)), the curve becomes narrower. This reflects that larger datasets provide more information, allowing us to pinpoint the most likely value of \(p\) with greater precision. The peak of each curve represents the <strong>maximum likelihood estimate (MLE)</strong>, the value of \(p\) that maximizes the likelihood function.</p> <p>Maximizing the <strong>likelihood</strong> to find MLE, directly can be cumbersome due to the product of many terms. However, we can simplify the process by taking the <strong>logarithm</strong> of the likelihood function. Since the natural logarithm is a monotonic function, maximizing the log-likelihood is equivalent to maximizing the likelihood itself. The log-likelihood function is:</p> <p>\begin{equation} \ell(p) = \log L(p) = \log \left( \prod_{i=1}^n p^{X_i} (1 - p)^{1 - X_i} \right) \end{equation}</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># define log-likelihood
</span><span class="k">def</span> <span class="nf">log_likelihood</span><span class="p">(</span><span class="n">trials</span><span class="p">,</span> <span class="n">p</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">sum_trials</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">(</span><span class="n">trials</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">sum_one_minus_trials</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sum</span><span class="p">([(</span><span class="mi">1</span><span class="o">-</span> <span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">trials</span> <span class="err"> </span><span class="p">])</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">log_lik</span> <span class="o">=</span> <span class="n">sum_trials</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="n">p</span><span class="p">)</span> <span class="o">+</span> <span class="n">sum_one_minus_trials</span><span class="o">*</span><span class="n">np</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="mi">1</span><span class="o">-</span><span class="n">p</span><span class="p">)</span>
<span class="err"> </span> <span class="err"> </span> <span class="n">mle</span> <span class="o">=</span> <span class="n">p</span><span class="p">[</span><span class="n">np</span><span class="p">.</span><span class="nf">argmax</span><span class="p">(</span><span class="n">log_lik</span><span class="p">)]</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">return</span> <span class="n">log_lik</span><span class="p">,</span> <span class="n">mle</span>

<span class="n">log_lik_1</span><span class="p">,</span> <span class="n">mle_1</span> <span class="o">=</span> <span class="nf">log_likelihood</span><span class="p">(</span><span class="n">trials_1</span><span class="p">,</span><span class="n">p_1</span><span class="p">)</span>
<span class="n">log_lik_2</span><span class="p">,</span> <span class="n">mle_2</span> <span class="o">=</span> <span class="nf">log_likelihood</span><span class="p">(</span><span class="n">trials_2</span><span class="p">,</span><span class="n">p_2</span><span class="p">)</span>
<span class="n">log_lik_3</span><span class="p">,</span> <span class="n">mle_3</span> <span class="o">=</span> <span class="nf">log_likelihood</span><span class="p">(</span><span class="n">trials_3</span><span class="p">,</span><span class="n">p_3</span><span class="p">)</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/LogLikelihood-480.webp 480w,/assets/img/LogLikelihood-800.webp 800w,/assets/img/LogLikelihood-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/LogLikelihood.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Just like the likelihood, the log-likelihood curve peaks at the MLE, which is indicated by the dashed red line in the plot. Notice how, for larger sample sizes, the log-likelihood curve becomes steeper around the MLE. This means that the likelihood sharply penalizes values of \(p\) that deviate from the MLE as we gather more data. The shape of the curves is consistent across sample sizes, but the curves shift downwards as \(N\) increases. This is a natural consequence of the log-likelihood being the sum of the log probabilities across all data points — with more data, this sum grows larger (in negative magnitude).<br/> The MLE turns out to be 0.2 which is nothing but the proportion of people who tested positive in the given sample. This is can be written as</p> <p>\begin{equation} \hat{p} = \frac{\sum_{i=1}^n X_i}{n} \end{equation}</p> <p>This tells us that the maximum likelihood estimate \(\hat{p}\) is simply the <strong>sample mean</strong> of the observed data.</p>]]></content><author><name></name></author><category term="ML-concepts"/><category term="statistics"/><category term="code"/><summary type="html"><![CDATA[MLE for discrete features]]></summary></entry><entry><title type="html">Exploring Prior, Likelihood, and Posterior Distributions</title><link href="https://krishna-das-m.github.io/blog/2024/bayes-theorem/" rel="alternate" type="text/html" title="Exploring Prior, Likelihood, and Posterior Distributions"/><published>2024-09-30T15:09:00+00:00</published><updated>2024-09-30T15:09:00+00:00</updated><id>https://krishna-das-m.github.io/blog/2024/bayes-theorem</id><content type="html" xml:base="https://krishna-das-m.github.io/blog/2024/bayes-theorem/"><![CDATA[<p>In this post, we’ll explore the relationship between <strong>prior distribution</strong>, <strong>likelihood</strong>, and <strong>posterior distribution</strong> using a practical example.</p> <h4 id="bayes-theorem">Bayes’ Theorem</h4> <p>Bayes’ Theorem helps us update our beliefs based on new evidence. Here’s the formula: \begin{equation} \overbrace{P(hypothesis | evidence)}^{\text{posterior}} = \frac{\overbrace{P(evidence| hypothesis)}^{\text{likelihood}} \overbrace{P(hypothesis)}^{\text{prior}}}{\underbrace{P(evidence)}_{\text{marginal}}} \end{equation}</p> <p>Where:</p> <ul> <li><strong>Posterior</strong>: How probable is our hypothesis given the observed evidence.</li> <li><strong>Likelihood</strong>: How probable is the evidence given that our hypothesis is true.</li> <li><strong>Prior</strong>: How probable was our hypothesis before observing the data.</li> <li><strong>Marginal</strong>: How probable is the new evidence under all possible hypothesis.</li> </ul> <hr/> <h4 id="the-scenario">The Scenario</h4> <p>Let’s walk through an example.</p> <p>Suppose you visit your doctor and get tested for a rare disease. Unfortunately, the test result is positive. Naturally, you want to know: “Given the positive result, what is the probability that I actually have the disease?” Since no medical test is 100% accurate, Bayes’ Theorem helps us answer this question. In the context of our current scenario, when comparing it to the general form of Bayes’ Theorem, the hypothesis we are testing is that a person has the disease (i.e., they test positive for it). The evidence corresponds to the observed data, specifically the results from the tests that indicate a positive outcome.</p> <hr/> <h4 id="breaking-down-the-terms">Breaking Down the Terms:</h4> <ol> <li> <p><strong>Prior Probability, \(P(Disease)\)</strong>:<br/> This is the probability of having the disease before considering the test result. It represents the incidence of the disease in the general population.<br/> For example, if the disease affects 1 in 1000 people, then:<br/> \(P(Disease) = 0.001\)</p> </li> <li> <p><strong>Likelihood, \(P(+ | Disease)\)</strong>:<br/> This is the probability of testing positive, given that you already have the disease. In other words, it’s the accuracy of the test in detecting the disease when it is present.<br/> Let’s assume the test has an accuracy of 99%, so:<br/> \(P(+ | Disease) = 0.99\)</p> </li> <li> <p><strong>Marginal, \(P(+)\)</strong>:<br/> This is the overall probability of testing positive, regardless of whether the person has the disease. It includes both true positives and false positives.<br/> It is calculated as:<br/> \(P(+) = P(Disease) P(+ | Disease) + P(Healthy) P(+ | Healthy)\)<br/> Here, \(P(Healthy) = 1 - P(Disease) = 0.999\), and \(P(+ | Healthy)\) is the probability of NOT having the disease and falsely identified positive by the test (1% = 0.01). So:<br/> \(P(+ | Healthy) = 0.01\)</p> </li> <li> <p><strong>Posterior Probability, \(P(Disease | +)\)</strong>:<br/> This is the updated probability of having the disease, given that the test result is positive. Using Bayes’ Theorem, we can compute this as:<br/> \(P(Disease | +) = \frac{P(Disease) P(+ | Disease)}{P(+) }\) Plugging in the values:<br/> \(P(Disease | +) = \frac{0.001 \times 0.99}{(0.001 \times 0.99) + (0.999 \times 0.01)} = 0.09016\)<br/> So, the probability that you actually have the disease, even after testing positive, is about <strong>9%</strong>.</p> </li> </ol> <hr/> <p>Now where do the distribution plots of prior, likelihood and posterior come from? Before diving into how we obtain the distributions for the <strong>prior</strong>, <strong>likelihood</strong>, and <strong>posterior</strong>, let’s introduce a change of variable to make the equation more intuitive. We’ll substitute <strong>Disease</strong> with <strong>\(\theta\)</strong>, which represents the probability that a person from the population will test positive. This allows us to express <strong>Bayes’ Theorem</strong> as:<br/> \begin{equation} P(\theta|+)=\frac{P(+|\theta)P(\theta)}{P(+)} \end{equation} Our goal is to estimate the parameter <strong>\(\theta\)</strong>, which is the probability that a random individual will test positive for the disease. To make this concept more concrete, let’s simulate a scenario where we conduct a total of 10 tests, out of which 2 people are positive (we’ll call this a <strong>success</strong>).</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code> <span class="c1"># Create bernoulli trials
</span> <span class="n">N</span> <span class="o">=</span> <span class="mi">10</span> <span class="c1">#total trials
</span> <span class="n">nDisease</span> <span class="o">=</span> <span class="mi">2</span> <span class="c1"># success
</span>
 <span class="c1"># Create a list with Disease (D) and Healthy (H) results
</span> <span class="n">trials</span> <span class="o">=</span> <span class="p">[</span><span class="sh">"</span><span class="s">D</span><span class="sh">"</span><span class="p">]</span> <span class="o">*</span> <span class="n">nDisease</span> <span class="o">+</span> <span class="p">[</span><span class="sh">"</span><span class="s">H</span><span class="sh">"</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="n">N</span> <span class="o">-</span> <span class="n">nDisease</span><span class="p">)</span>

 <span class="c1"># Shuffle the sequence to randomize the order of trials
</span> <span class="n">random</span><span class="p">.</span><span class="nf">shuffle</span><span class="p">(</span><span class="n">trials</span><span class="p">)</span>

 <span class="nf">print</span><span class="p">(</span><span class="n">trials</span><span class="p">)</span>
 <span class="p">[</span><span class="sh">'</span><span class="s">H</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">H</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">H</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">H</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">H</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">H</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">H</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">D</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">H</span><span class="sh">'</span><span class="p">,</span> <span class="sh">'</span><span class="s">D</span><span class="sh">'</span><span class="p">]</span>
</code></pre></div></div> <hr/> <h4 id="the-prior-distribution"><strong>The Prior Distribution</strong></h4> <p>Let’s assume we don’t have any specific information about the proportion of people who have the disease, so we don’t know the exact value of \(P(\theta)\). Instead of assuming a single fixed value, we’ll consider a range of possible values for \(P(\theta)\).<br/> To account for this uncertainty, we’ll generate 10 random values between 0 and 1, which will represent potential probabilities for the prevalence of the disease in the population. This helps us explore various possible scenarios when estimating the likelihood of having the disease based on a positive test result.<br/> Here’s how we generate these random values:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="n">scipy.stats</span> <span class="kn">import</span> <span class="n">beta</span>

<span class="c1"># Disease = np.random.random(10)
</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">N</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mi">10</span>
<span class="n">h</span> <span class="o">=</span> <span class="p">(</span><span class="n">stop</span><span class="o">-</span><span class="n">start</span><span class="p">)</span><span class="o">/</span><span class="n">N</span>
<span class="n">theta</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">arange</span><span class="p">(</span><span class="n">start</span><span class="p">,</span> <span class="n">stop</span><span class="p">,</span> <span class="n">h</span><span class="p">)</span>
</code></pre></div></div> <p>At this stage, <code class="language-plaintext highlighter-rouge">theta</code> contains a set of values representing possible probabilities of having the disease. However, these values don’t yet form a probability distribution because the sum of \(P(\theta)\) is not equal to 1. If desired, we could adjust the range of <code class="language-plaintext highlighter-rouge">theta</code> (for example, using values from 0 to 10), but in that case, we would need to normalize the values.</p> <p>Next, we need to choose a distribution for the <strong>prior</strong>. A suitable choice is the <strong>beta distribution</strong>, which is defined over the interval \([0, 1]\), making it perfect for modeling probabilities like \(\theta\).</p> <p>We can specify the prior distribution using the beta distribution:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Define prior distribution
</span><span class="n">a</span> <span class="p">,</span> <span class="n">b</span><span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">10</span>
<span class="n">dist</span> <span class="o">=</span> <span class="nf">beta</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="n">Ptheta</span> <span class="o">=</span> <span class="n">dist</span><span class="p">.</span><span class="nf">pdf</span><span class="p">(</span><span class="n">theta</span><span class="p">)</span>
<span class="c1"># Normalize so that values sum to 1
</span><span class="n">Ptheta</span> <span class="o">=</span> <span class="n">Ptheta</span> <span class="o">/</span> <span class="nf">sum</span><span class="p">(</span><span class="n">Ptheta</span><span class="p">)</span>
<span class="c1"># print(pTheta)
</span></code></pre></div></div> <p>The array <code class="language-plaintext highlighter-rouge">Ptheta</code> gives us the prior probability distribution. This represents our <strong>prior belief</strong> about the possible values of \(P(\theta)\) before observing any new data, such as the results of the test.</p> <h4 id="the-likelihood"><strong>The Likelihood</strong></h4> <p><strong>The likelihood function</strong> is simply the joint probability of observing the data we have. For a set of test results, the likelihood function is expressed as:<br/> \(P(+|\theta)=\prod_i^N P(+_i|\theta)\) This is the product of the probabilities of observing each positive test result for a given \(\theta\). Specifically, the likelihood function for this binary event (positive or negative test result) can be written using the <strong>binomial distribution</strong>:</p> <p>\(P(+|\theta)=\binom{N}{k}\theta^k(1-\theta)^{N-k}\)</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Likelihood
</span><span class="n">PPositiveGiventheta</span> <span class="o">=</span> <span class="nf">comb</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">nDisease</span><span class="p">)</span><span class="o">*</span><span class="n">theta</span><span class="o">**</span><span class="n">nDisease</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">theta</span><span class="p">)</span><span class="o">**</span><span class="n">nHealthy</span>
</code></pre></div></div> <h4 id="the-posterior-distribution"><strong>The Posterior Distribution</strong></h4> <p>With both the <strong>prior</strong> and <strong>likelihood</strong> in hand, we can now calculate the <strong>posterior distribution</strong> using Bayes’ Theorem. The only remaining part to compute is the denominator of Bayes’ Theorem, which acts as a normalization factor, ensuring that the posterior probabilities sum to 1.</p> <p>Using the following Python code, we can calculate the <strong>marginal probability</strong> (the denominator) and the posterior:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># marginal probability
</span><span class="n">PPositive</span> <span class="o">=</span> <span class="nf">sum</span><span class="p">(</span><span class="n">PPositiveGiventheta</span> <span class="o">*</span> <span class="n">Ptheta</span><span class="p">)</span>
<span class="c1"># posterior probability
</span><span class="n">PthetaGivenPositive</span> <span class="o">=</span> <span class="n">PPositiveGiventheta</span><span class="o">*</span><span class="n">Ptheta</span> <span class="o">/</span> <span class="n">PPositive</span>
</code></pre></div></div> <p>Now let’s take a look at what we’ve calculated for each value of \(\theta\):</p> <table> <thead> <tr> <th>theta</th> <th>prior</th> <th>likelihood</th> <th>posterior</th> </tr> </thead> <tbody> <tr> <td>0.0</td> <td>0.0000</td> <td>0.0000</td> <td>0.0000</td> </tr> <tr> <td>0.1</td> <td>0.0545</td> <td>0.1937</td> <td>0.1106</td> </tr> <tr> <td>0.2</td> <td>0.0970</td> <td>0.3020</td> <td>0.3065</td> </tr> <tr> <td>0.3</td> <td>0.1273</td> <td>0.2335</td> <td>0.3110</td> </tr> <tr> <td>0.4</td> <td>0.1455</td> <td>0.1209</td> <td>0.1841</td> </tr> <tr> <td>0.5</td> <td>0.1515</td> <td>0.0439</td> <td>0.0697</td> </tr> <tr> <td>0.6</td> <td>0.1455</td> <td>0.0106</td> <td>0.0162</td> </tr> <tr> <td>0.7</td> <td>0.1273</td> <td>0.0014</td> <td>0.0019</td> </tr> <tr> <td>0.8</td> <td>0.0970</td> <td>0.0001</td> <td>0.0001</td> </tr> <tr> <td>0.9</td> <td>0.0545</td> <td>0.0000</td> <td>0.0000</td> </tr> </tbody> </table> <p>Starting with the <strong>prior</strong> column, we can see that, based on the beta distribution \(\beta(2,2)\), most of the prior probability is centered around middle values of \(\theta\). This reflects an initial belief that the probability of having the disease is likely to be between 0.4 and 0.6, while assigning smaller probabilities to extreme values close to 0 or 1. The <strong>likelihood</strong>, derived from the observed data, suggests that the most likely values for \(\theta\) are between 0.2 and 0.3. Specifically, the maximum likelihood estimate for \(\theta\) is 0.2, which corresponds to the proportion of positive test results observed in the sample. As a result, the <strong>posterior distribution</strong> represents an update to our prior belief based on the likelihood of the data. The posterior shifts the bulk of the probability away from the prior’s most likely values (around 0.4–0.6) and moves it toward the data-driven estimate of \(\theta\) around 0.2. If we look at the mean of the posterior,</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">posteriorMean</span> <span class="o">=</span> <span class="nf">sum</span><span class="p">(</span><span class="n">PDiseaseGivenPositive</span> <span class="o">*</span> <span class="n">theta</span><span class="p">)</span>
<span class="n">posteriorMean</span><span class="p">.</span><span class="nf">round</span><span class="p">(</span><span class="mi">4</span><span class="p">)</span>
<span class="mf">0.285</span>
</code></pre></div></div> <p>We can perhaps understand this further via the following visualizations. When using a <strong>beta prior</strong> of \(\beta(2,2)\), we start with a fairly weak belief about the probability \(\theta\) (testing positive for the disease). This prior distribution is fairly spread out, indicating that we don’t have a strong belief in any particular value of \(\theta\). There’s no sharp peak—suggesting we are open to a wide range of possibilities for the true value of \(\theta\). The <strong>likelihood function</strong>, based on the observed data, peaks around \(\theta = 0.1\), indicating that the data suggests this is the most likely value for the probability of a positive test. However, since our sample size is small, the likelihood still has some spread, reflecting uncertainty in our estimate. The <strong>posterior distribution</strong>—in green—represents the updated belief after combining the prior with the likelihood. It shows a peak around \(\theta = 0.2\), reflecting that the data is suggesting a slightly higher value for \(\theta\). However, since we’re combining a weak prior and a small sample, the posterior still has noticeable spread, indicating uncertainty remains.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/distributions_prior_beta_2_2-480.webp 480w,/assets/img/distributions_prior_beta_2_2-800.webp 800w,/assets/img/distributions_prior_beta_2_2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/distributions_prior_beta_2_2.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/distributions_prior_beta_10_10-480.webp 480w,/assets/img/distributions_prior_beta_10_10-800.webp 800w,/assets/img/distributions_prior_beta_10_10-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/distributions_prior_beta_10_10.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Now, consider a stronger prior, \(\beta(10,10)\), along with a larger dataset (100 samples). The prior distribution is more concentrated, reflecting a stronger initial belief about \(\theta\)—in this case, that it’s around 0.5. The <strong>likelihood function</strong> with the larger sample is also much sharper and concentrated around \(\theta = 0.2\). This sharpness reflects the informativeness of the data: with more samples, the data has reduced uncertainty, and the peak clearly suggests that \(\theta = 0.2\) is the most likely value. Finally, the <strong>posterior distribution</strong> in this case is sharper and more concentrated around \(\theta = 0.2\), indicating much higher certainty about the estimate of \(\theta\). With the larger dataset, the prior has much less influence compared to the likelihood, which dominates and drives the sharper posterior.</p> <p>Now, let’s look what happens when we use the posterior distribution from the previous step as the new prior. This updated prior now reflects a more informed belief about the unknown parameter \(\theta\). Since this new prior is derived from the posterior of the previous round, it’s much more concentrated compared to the original prior we started with. We now have a much stronger belief that \(\theta\) lies within a narrow range (around 0.15 in this case). The likelihood function looks almost the same as in the previous figure and still shows a peak around the same value of \(\theta\), indicating that the observed data strongly suggests that \(\theta\) falls within a same range. The updated posterior distribution is even sharper and more concentrated than before, reflecting a very strong belief about the value of \(\theta\). Compared to the earlier posterior (based on a broader prior), this one is peaked around 0.12, showing that we now have an even greater degree of certainty about \(\theta\).<br/> The key takeaway here is that as we gather more data and update our beliefs (using Bayes’ Theorem), our estimates become more precise. The prior becomes more informative, and the posterior narrows further, reflecting reduced uncertainty about the unknown parameter .</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/distributions_prior_posterior-480.webp 480w,/assets/img/distributions_prior_posterior-800.webp 800w,/assets/img/distributions_prior_posterior-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/distributions_prior_posterior.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Bayesian updating is a powerful method that allows us to continuously refine our estimates as new data becomes available. This process is iterative: we start with an initial belief (the <strong>prior</strong>), update it with evidence (the <strong>likelihood</strong>), and obtain a revised belief (the <strong>posterior</strong>). The posterior then serves as the new prior for the next round of updates. Let’s see how this works in practice by performing <strong>Bayesian updating</strong> in Python.</p> <p>Below is a Python implementation that demonstrates the sequential nature of this process over 10 updates:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># Bayesian updating
</span><span class="k">def</span> <span class="nf">bayesian_update</span><span class="p">(</span><span class="n">bayes_df</span><span class="p">,</span> <span class="n">n</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">bayes_df</span> <span class="o">=</span> <span class="n">bayes_df</span><span class="p">[[</span><span class="sh">'</span><span class="s">theta</span><span class="sh">'</span><span class="p">,</span><span class="sh">'</span><span class="s">posterior</span><span class="sh">'</span><span class="p">]].</span><span class="nf">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="sh">'</span><span class="s">posterior</span><span class="sh">'</span><span class="p">:</span><span class="sh">'</span><span class="s">prior</span><span class="sh">'</span><span class="p">})</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">bayes_df</span><span class="p">[</span><span class="sh">'</span><span class="s">likelihood</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="nf">comb</span><span class="p">(</span><span class="n">N</span><span class="p">,</span> <span class="n">nDisease</span><span class="p">)</span><span class="o">*</span><span class="n">theta</span><span class="o">**</span><span class="n">nDisease</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">theta</span><span class="p">)</span><span class="o">**</span><span class="n">nHealthy</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">marginal</span> <span class="o">=</span> <span class="p">(</span><span class="n">bayes_df</span><span class="p">[</span><span class="sh">'</span><span class="s">likelihood</span><span class="sh">'</span><span class="p">]</span><span class="o">*</span><span class="n">bayes_df</span><span class="p">[</span><span class="sh">'</span><span class="s">prior</span><span class="sh">'</span><span class="p">]).</span><span class="nf">sum</span><span class="p">()</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">bayes_df</span><span class="p">[</span><span class="sh">'</span><span class="s">posterior</span><span class="sh">'</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="n">bayes_df</span><span class="p">[</span><span class="sh">'</span><span class="s">likelihood</span><span class="sh">'</span><span class="p">]</span><span class="o">*</span><span class="n">bayes_df</span><span class="p">[</span><span class="sh">'</span><span class="s">prior</span><span class="sh">'</span><span class="p">])</span><span class="o">/</span><span class="n">marginal</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="n">posteriorMean</span> <span class="o">=</span> <span class="nf">sum</span><span class="p">(</span><span class="n">bayes_df</span><span class="p">[</span><span class="sh">'</span><span class="s">posterior</span><span class="sh">'</span><span class="p">]</span> <span class="o">*</span> <span class="n">bayes_df</span><span class="p">[</span><span class="sh">'</span><span class="s">theta</span><span class="sh">'</span><span class="p">])</span>
<span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="err"> </span> <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">'</span><span class="s">Posterior mean after </span><span class="si">{</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="si">}</span><span class="s"> update is: </span><span class="si">{</span><span class="nf">round</span><span class="p">(</span><span class="n">posteriorMean</span><span class="p">,</span><span class="mi">3</span><span class="p">)</span><span class="si">}</span><span class="sh">'</span><span class="p">)</span>

<span class="err"> </span> <span class="err"> </span> <span class="k">return</span> <span class="n">bayes_df</span>

<span class="n">bayes_update_df</span> <span class="o">=</span> <span class="nf">bayesian_update</span><span class="p">(</span><span class="n">bayes_df</span><span class="p">,</span><span class="n">n</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>
</code></pre></div></div> <p>Running the above code produces the following results, showing how the <strong>posterior mean</strong> changes after each update:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">Posterior</span> <span class="n">mean</span> <span class="n">after</span> <span class="mi">1</span> <span class="n">update</span> <span class="ow">is</span><span class="p">:</span> <span class="mf">0.136</span>
<span class="n">Posterior</span> <span class="n">mean</span> <span class="n">after</span> <span class="mi">2</span> <span class="n">update</span> <span class="ow">is</span><span class="p">:</span> <span class="mf">0.125</span>
<span class="n">Posterior</span> <span class="n">mean</span> <span class="n">after</span> <span class="mi">3</span> <span class="n">update</span> <span class="ow">is</span><span class="p">:</span> <span class="mf">0.119</span>
<span class="n">Posterior</span> <span class="n">mean</span> <span class="n">after</span> <span class="mi">4</span> <span class="n">update</span> <span class="ow">is</span><span class="p">:</span> <span class="mf">0.115</span>
<span class="n">Posterior</span> <span class="n">mean</span> <span class="n">after</span> <span class="mi">5</span> <span class="n">update</span> <span class="ow">is</span><span class="p">:</span> <span class="mf">0.113</span>
<span class="n">Posterior</span> <span class="n">mean</span> <span class="n">after</span> <span class="mi">6</span> <span class="n">update</span> <span class="ow">is</span><span class="p">:</span> <span class="mf">0.111</span>
<span class="n">Posterior</span> <span class="n">mean</span> <span class="n">after</span> <span class="mi">7</span> <span class="n">update</span> <span class="ow">is</span><span class="p">:</span> <span class="mf">0.11</span>
<span class="n">Posterior</span> <span class="n">mean</span> <span class="n">after</span> <span class="mi">8</span> <span class="n">update</span> <span class="ow">is</span><span class="p">:</span> <span class="mf">0.109</span>
<span class="n">Posterior</span> <span class="n">mean</span> <span class="n">after</span> <span class="mi">9</span> <span class="n">update</span> <span class="ow">is</span><span class="p">:</span> <span class="mf">0.108</span>
<span class="n">Posterior</span> <span class="n">mean</span> <span class="n">after</span> <span class="mi">10</span> <span class="n">update</span> <span class="ow">is</span><span class="p">:</span> <span class="mf">0.107</span>
</code></pre></div></div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/distributions_prior_posterior_10-480.webp 480w,/assets/img/distributions_prior_posterior_10-800.webp 800w,/assets/img/distributions_prior_posterior_10-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/distributions_prior_posterior_10.jpg" class="img-fluid rounded z-depth-1 mx-auto d-block" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>This illustrates the <strong>sequential nature of Bayesian updating</strong>. This iterative process is fundamental to <strong>Bayesian inference</strong> and demonstrates how our understanding of a parameter improves with each new piece of evidence, making Bayesian methods highly suitable for dynamic, real-world problems where data comes in sequentially over time.</p>]]></content><author><name></name></author><category term="ML-concepts"/><category term="statistics"/><category term="code"/><category term="probability"/><summary type="html"><![CDATA[Understanding the basics of Bayes' theorem]]></summary></entry></feed>